{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "33958a82-a012-4dcc-ad1c-6791dbd613cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.preprocessing\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "from functools import reduce\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1f7c3d8-4947-49ac-85c9-e7cfcc76827f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Excel file\n",
    "df = pd.read_excel('Parts and Dimesions.xlsx')\n",
    "#print(df.head)\n",
    "\n",
    "# Do not use the 'Operator' or 'Item_No' column\n",
    "df = df.drop(columns=['Item_No', 'Operator'])\n",
    "#print(df.head)\n",
    "\n",
    "# Remove rows with missing cells\n",
    "df_nomissing = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65b9a684-f212-4a07-bf1e-7acacd49dccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#print(type(df_nomissing))\\nprint(df_nomissing)'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###TEST CELL###\n",
    "'''\n",
    "#print(type(df_nomissing))\n",
    "print(df_nomissing)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d5d4248-97d4-441b-ac01-a0d6d04a1325",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_startingData = \"C:\\\\Users\\\\J\\\\dataframes_startingData\"\n",
    "df_nomissing.to_csv(directory_startingData, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5a3d3b-d57d-4b62-8950-1bd67be0b672",
   "metadata": {},
   "source": [
    "From this point onward, this dataset will be referred to as our \"starting dataset\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f492d67e-6d3c-4b28-9eb7-a3b38d34088d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zscoreGlobalOutlier(df, stdev_threshold):\n",
    "    df_global_outlier_removed = []\n",
    "    \n",
    "    for threshold in stdev_threshold:\n",
    "        # Calculate the z-score for each column\n",
    "        z_scores = stats.zscore(df)\n",
    "\n",
    "        # Identify outliers\n",
    "        outliers_high = z_scores > threshold\n",
    "        outliers_low = z_scores < threshold*-1\n",
    "\n",
    "        # Remove outliers from the DataFrame\n",
    "        df_global_outlier_high_removed = df[~outliers_high.any(axis=1)]\n",
    "        df_global_outlier_removed.append(df_global_outlier_high_removed[~outliers_low.any(axis=1)])\n",
    "\n",
    "    return df_global_outlier_removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36017452-ce2f-4b67-8858-90f55a29eea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df_dict_noOutliers(df_list, threshold_list, df_dict):    \n",
    "    # Get the starting index position\n",
    "    start_index = len(df_dict)\n",
    "    \n",
    "    # Iterate over each dataframe and threshold in the lists\n",
    "    for index, (df, threshold) in enumerate(zip(df_list, threshold_list)):\n",
    "        # Create a dictionary to store dataframe and threshold information\n",
    "        entry = {'dataframe': df, 'stdev threshold': threshold}\n",
    "\n",
    "        # Add the entry to the df_dict with the index as the key\n",
    "        df_dict[index] = entry\n",
    "\n",
    "    print(\"Dictionary: dataframe, stdev_thresh\")\n",
    "    return df_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fef14103-4e81-4bc9-bb3e-01ea0ca3af61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\J\\AppData\\Local\\Temp\\ipykernel_33892\\1368169788.py:14: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_global_outlier_removed.append(df_global_outlier_high_removed[~outliers_low.any(axis=1)])\n",
      "C:\\Users\\J\\AppData\\Local\\Temp\\ipykernel_33892\\1368169788.py:14: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_global_outlier_removed.append(df_global_outlier_high_removed[~outliers_low.any(axis=1)])\n"
     ]
    }
   ],
   "source": [
    "df1 = df_nomissing.copy()\n",
    "stdev_threshold = [2,3]\n",
    "a = zscoreGlobalOutlier(df1, stdev_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7961bc4b-00d7-4f5d-adc4-333093ddeed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(a)'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###TEST CELL###\n",
    "'''\n",
    "print(a)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c93be83c-e3ac-46ef-9d06-2926df50d382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary: dataframe, stdev_thresh\n"
     ]
    }
   ],
   "source": [
    "df_dict_full = {}\n",
    "df_dict_full = create_df_dict_noOutliers(a, stdev_threshold, df_dict_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7ad2f93-00a9-4550-8828-e6289a2fc217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(len(df_dict_full))\\nprint(df_dict_full[0])'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###TEST CELL###\n",
    "'''\n",
    "print(len(df_dict_full))\n",
    "print(df_dict_full[0])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1fb7242e-2412-4127-a782-6fa71ab09755",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dataframes(df_dict):\n",
    "    dataframes = []\n",
    "    for entry in df_dict.values():\n",
    "        dataframes.append(entry['dataframe'])\n",
    "    return dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "880e4430-a0a8-4dcd-9ed3-2f77c39d86fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_R_full = extract_dataframes(df_dict_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2bdb0ec1-610d-4e0c-a391-a71e92158223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(type(df_for_R_full))\\nprint(len(df_for_R_full))\\nprint(df_for_R_full)'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###TEST CELL###\n",
    "'''\n",
    "print(type(df_for_R_full))\n",
    "print(len(df_for_R_full))\n",
    "print(df_for_R_full)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1aa92ca9-53c1-4807-a670-1b6d75d5bc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_outputs(directory, df_list, filename):\n",
    "    # Create directory if it doesn't exist\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "    # Iterate over the list of dataframes\n",
    "    for i, df in enumerate(df_list):\n",
    "        # Create the full file path\n",
    "        file_path = os.path.join(directory, f\"{filename}_{i}.csv\")\n",
    "\n",
    "        # Save the dataframe as a CSV file\n",
    "        df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c6475fb-c85a-4a57-9fa1-8d0cd9e33875",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_full = \"C:\\\\Users\\\\J\\\\dataframes_full\"\n",
    "filename = \"df_full\"\n",
    "save_outputs(directory_full, df_for_R_full, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a8b106-4509-41a0-a608-417a2f86b6c0",
   "metadata": {},
   "source": [
    "At this point, we have 2 full datasets. They exist in a dictionary for easy reference to remind ourselves of what preprocessing has occurred. The step not mention, but performed, was removing NaN. These two datasets have also been saved as .csv files to my (your) local machine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69746baa-b2c0-4ac0-ad05-015d14e9d90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomly_remove_indices(df_list, percentage_list):\n",
    "    df_merged_list = []\n",
    "    df_mergedGT_list = []\n",
    "\n",
    "    for df in df_list:\n",
    "        for percentage in percentage_list:\n",
    "            indices_to_remove = {}\n",
    "            groundTruth = {}\n",
    "            new_df = {}\n",
    "            num_indices = int(len(df) * percentage / 100)\n",
    "\n",
    "            for column in df.columns:\n",
    "                indices_to_remove[column] = np.random.choice(df[column].index, size=num_indices, replace=False)\n",
    "                groundTruth[column] = df[column].loc[indices_to_remove[column]].copy()\n",
    "                new_df[column] = df[column].copy()\n",
    "                new_df[column].loc[indices_to_remove[column]] = np.nan\n",
    "\n",
    "            # Merge the new DataFrames\n",
    "            df_merged = pd.concat(new_df.values(), axis=1)\n",
    "            df_mergedGT = pd.concat(groundTruth.values(), axis=1)\n",
    "            df_mergedGT = df_mergedGT.sort_index()\n",
    "\n",
    "            # Append the merged DataFrames to the respective lists\n",
    "            df_merged_list.append(df_merged)\n",
    "            df_mergedGT_list.append(df_mergedGT)\n",
    "\n",
    "    return df_merged_list, df_mergedGT_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0bf0a1c0-2bb2-470f-a7dd-adc5bff3c896",
   "metadata": {},
   "outputs": [],
   "source": [
    "percent = [5, 15, 35]\n",
    "aa = randomly_remove_indices(a, percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "42806c71-ee43-4706-8f09-64fd7229e6c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#print(len(aa))\\n#print(len(aa[0]))\\nprint(aa[1])'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###TEST CELL###\n",
    "'''\n",
    "#print(len(aa))\n",
    "#print(len(aa[0]))\n",
    "print(aa[1])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cc977020-2118-4c30-987f-20dbdecce962",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dict_for_pre_imputation(df_list, df_missing_dict, threshold_list, percentage_list):\n",
    "    dataset_index = 0\n",
    "\n",
    "    # the point of this is to make sure as the dictionary fills, it is correctly tracking \n",
    "    # the correct pre-porcessing procedure for each\n",
    "    for v_index, v_value in enumerate(threshold_list):\n",
    "        for vv_value in percentage_list:\n",
    "            entry = {'dataframe': df_list[v_index], 'stdev threshold': v_value, 'missing_percent' : vv_value}\n",
    "            df_missing_dict[dataset_index] = entry\n",
    "            dataset_index += 1\n",
    "\n",
    "    print(\"Dictionary: dataframe, stdev_thresh, missing_percent\")\n",
    "    return df_missing_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7785e649-9f46-4d41-a7b3-8d17357b8e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary: dataframe, stdev_thresh, missing_percent\n"
     ]
    }
   ],
   "source": [
    "stdev_threshold = [2,3]\n",
    "percent = [5, 15, 35]\n",
    "preimputation_dict = {}\n",
    "preimputation_dict = create_dict_for_pre_imputation(aa[0], preimputation_dict, stdev_threshold, percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "884fd97a-1cb8-4dcb-a9d3-63d87ebcbab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nprint(type(q))\\nprint(len(q))\\nprint(q[1]['dataframe'])\\nprint(type(qq))\\nprint(len(qq))\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###TEST CELL###\n",
    "'''\n",
    "print(type(q))\n",
    "print(len(q))\n",
    "print(q[1]['dataframe'])\n",
    "print(type(qq))\n",
    "print(len(qq))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c487278e-f157-4d06-bf24-61cd7f6b2c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_R_missing = extract_dataframes(preimputation_dict)\n",
    "directory_missing = \"C:\\\\Users\\\\J\\\\dataframes_missing\"\n",
    "filename1 = \"df_missing\"\n",
    "save_outputs(directory_missing, df_for_R_missing, filename1)\n",
    "\n",
    "#df_for_R_GT = extract_dataframes(qq)\n",
    "#directory_GT = \"C:\\\\Users\\\\J\\\\dataframes_GT\"\n",
    "#filename2 = \"df_GT\"\n",
    "#save_outputs(directory_GT, df_for_R_GT, filename2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cb508e-6334-482d-8e95-0434e5644cc7",
   "metadata": {},
   "source": [
    "Starting from out \"starting dataset\". We removed outliers by 2 criteria, resulting in 2 unique datasets. Each dataset then had a random amount of data removed. \n",
    "\n",
    "To *attempt* to avoid undue bias, the percent missing was applied to each column. There is a non-zero chance empty rows may have been generated.\n",
    "\n",
    "3 amounts of missingness were performed on each of the 2 datasets, resulting in 6 unique datasets that contain missing data AND 6 unique datasets that contain the values that were removed. The index values from the \"starting dataset\" have been maintained in all 12 datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b6c65774-d6d8-43ac-9e92-4e90b3504b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def miceMethod(df_list, max_iter_list):\n",
    "    df_MICE_imputed_list = []\n",
    "    df_imputed_values_list = []\n",
    "    \n",
    "    for df in df_list:\n",
    "        for max_iterA in max_iter_list:\n",
    "            # Create an instance of the MICE imputer\n",
    "            mice_imputer = IterativeImputer(max_iter=max_iterA)\n",
    "\n",
    "            # Impute missing values using the MICE algorithm\n",
    "            df_imputed = mice_imputer.fit_transform(df)\n",
    "\n",
    "            # Convert the imputed array back to a DataFrame\n",
    "            df_MICE_imputed = pd.DataFrame(df_imputed, columns=df.columns, index=df.index)\n",
    "\n",
    "            # Create a DataFrame with just the imputed values\n",
    "            df_imputed_values = df_MICE_imputed[df.isna()]\n",
    "\n",
    "            # Append the imputed DataFrames to the respective lists\n",
    "            df_MICE_imputed_list.append(df_MICE_imputed)\n",
    "            df_imputed_values_list.append(df_imputed_values)\n",
    "\n",
    "    return df_MICE_imputed_list, df_imputed_values_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2dce0adb-2121-4ada-b2dd-8b6793605f15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#aa[0] is missing datasets\\nprint(type(aa[0]))\\nprint(len(aa[0]))'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###TEST CELL###\n",
    "'''\n",
    "#aa[0] is missing datasets\n",
    "print(type(aa[0]))\n",
    "print(len(aa[0]))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "abebd9b0-32a6-4693-98e3-4e94725891bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\J\\anaconda3\\envs\\r_environment_in_jupyternotbook\\lib\\site-packages\\sklearn\\impute\\_iterative.py:713: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "C:\\Users\\J\\anaconda3\\envs\\r_environment_in_jupyternotbook\\lib\\site-packages\\sklearn\\impute\\_iterative.py:713: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "C:\\Users\\J\\anaconda3\\envs\\r_environment_in_jupyternotbook\\lib\\site-packages\\sklearn\\impute\\_iterative.py:713: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "max_iter_list = [3, 5, 10]\n",
    "w = miceMethod(aa[0], max_iter_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4e2282b2-634a-43bb-8018-7d677fe52ffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#print(w)\\nprint(type(w))\\nprint(len(w))\\nprint(type(w[0]))\\nprint(len(w[0]))\\nprint(type(w[1]))\\nprint(len(w[1]))\\nprint(type(w[0][0]))\\nprint(len(w[0][0]))'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###TEST CELL###\n",
    "'''\n",
    "#print(w)\n",
    "print(type(w))\n",
    "print(len(w))\n",
    "print(type(w[0]))\n",
    "print(len(w[0]))\n",
    "print(type(w[1]))\n",
    "print(len(w[1]))\n",
    "print(type(w[0][0]))\n",
    "print(len(w[0][0]))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "51c62061-46f3-4d0d-a017-8710b145b783",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dict_for_PYMICE_imputation(df_list, df_PYMICE_dict, threshold_list, percentage_list, max_iter_list):\n",
    "    dataset_index = 0\n",
    "\n",
    "    # build and layer so that the correct preprocessing is matintained with each dataset\n",
    "    for v_index, v_value in enumerate(threshold_list):\n",
    "        for vv_value in percentage_list:\n",
    "            for vvv_value in max_iter_list:\n",
    "                entry = {'dataframe': df_list[v_index], 'stdev_thresh': v_value,\n",
    "                         'missing_percent' : vv_value, 'iterations' : vvv_value}\n",
    "                df_PYMICE_dict[dataset_index] = entry\n",
    "                dataset_index += 1\n",
    "\n",
    "    print(\"Dictionary: dataframe, stdev_thresh, missing_percent, iterations\")\n",
    "    return df_PYMICE_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "072a64fc-1ecf-48f6-9339-1c346831b4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_dict_without_dataframe(df_PYMICE_dict, index):\n",
    "    entry = df_PYMICE_dict[index]\n",
    "    keys_to_exclude = ['dataframe']  # Keys to exclude from printing\n",
    "\n",
    "    print(f\"Index: {index}\")\n",
    "    for key, value in entry.items():\n",
    "        if key not in keys_to_exclude:\n",
    "            print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0d001e0e-6b62-4d28-a64b-12198c225c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary: dataframe, stdev_thresh, missing_percent, iterations\n",
      "Dictionary: dataframe, stdev_thresh, missing_percent, iterations\n"
     ]
    }
   ],
   "source": [
    "z = {}\n",
    "zz = {}\n",
    "full_imputed_dict = create_dict_for_PYMICE_imputation(w[0], z, stdev_threshold, percent, max_iter_list)\n",
    "just_imputed_dict = create_dict_for_PYMICE_imputation(w[1], zz, stdev_threshold, percent, max_iter_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e82e0305-3d90-48a8-ac8d-4ebe947e0075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nprint(type(z))\\nprint(len(z))\\nprint(z[1])\\nprint(z[1]['dataframe'])\\nprint(print_dict_without_dataframe(z))\\n#print(type(zz))\\n#print(len(zz))\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###TEST CELL###\n",
    "'''\n",
    "print(type(z))\n",
    "print(len(z))\n",
    "print(z[1])\n",
    "print(z[1]['dataframe'])\n",
    "print(print_dict_without_dataframe(z))\n",
    "#print(type(zz))\n",
    "#print(len(zz))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9d9da75e-e0b0-44c7-a014-c3bbeae357eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_R_imputedFull = extract_dataframes(z)\n",
    "directory_imputedFull = \"C:\\\\Users\\\\J\\\\dataframes_imputedFull\"\n",
    "filename3 = \"df_imputedFull\"\n",
    "save_outputs(directory_imputedFull, df_for_R_imputedFull, filename3)\n",
    "\n",
    "df_for_R_justImputed = extract_dataframes(zz)\n",
    "directory_justImputed = \"C:\\\\Users\\\\J\\\\dataframes_justImputed\"\n",
    "filename4 = \"df_justImputed\"\n",
    "save_outputs(directory_justImputed, df_for_R_justImputed, filename4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c54cc4-7b90-4847-b504-bb9c933b3d16",
   "metadata": {},
   "source": [
    "From our \"starting dataset\", 2 different outlier thresholds, 3 degrees of missingness, and on each of those datasets 3 MICE imputations were performed, with increasing numbers of imputations. This has generated 18 unique datasets. In one file, the 18 unique datasets are maintained as the full datasets, on the other, the datasets are just the imputed values, with NaN everywhere else.\n",
    "\n",
    "Very important to note: the order of these are imperative. As 3 MICE datasets were generated from 1 missing dataset, there is 1 ground truth for 3 MICE datasets. \n",
    "\n",
    "This means that if MICE[0:3] are built from missing[0], they utilize groundTruth[0]. MICE[3:6] from missing[1] utilize groundTruth[1], etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bae913f9-fe54-412d-9fca-8809d1646726",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NaNfilter(df_list):\n",
    "    filtered_dfs = []  # List to store the filtered DataFrames\n",
    "    \n",
    "    for df in df_list:\n",
    "        filtered_cols = []  # List to store filtered columns\n",
    "        \n",
    "        for column in df.columns:\n",
    "            filtered_col = df[column].dropna()  # Drop NaN values\n",
    "            filtered_cols.append(filtered_col)  # Store filtered column in the list\n",
    "        \n",
    "        # Combine filtered columns into a new DataFrame\n",
    "        filtered_imputes = pd.concat(filtered_cols, axis=1)\n",
    "        \n",
    "        # Add the DataFrame to the list\n",
    "        filtered_dfs.append(filtered_imputes)\n",
    "    \n",
    "    return filtered_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fa7a02b7-8016-408b-a1dd-d37c5a1166bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#w[1] is just the imputed values\n",
    "#aa[1] is the ground truth values\n",
    "imputed_values = w[1]\n",
    "GT = aa[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "732f75e3-ca91-407a-9e45-40968395bc9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#print(imputed_values)\\nprint(len(imputed_values)) # 3 imputes for each GT/ this makes sense\\n#print(GT)\\nprint(len(GT))\\nprint(len(GT[0]))\\n#print(GT[0])'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###TEST CELL###\n",
    "'''\n",
    "#print(imputed_values)\n",
    "print(len(imputed_values)) # 3 imputes for each GT/ this makes sense\n",
    "#print(GT)\n",
    "print(len(GT))\n",
    "print(len(GT[0]))\n",
    "#print(GT[0])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "60e9ebf8-0a24-45ba-89ce-446f7eab4495",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed = NaNfilter(imputed_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "85eb9be2-864c-4dc9-9018-72aa8bcd9d75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(type(G_T))\\nprint(type(imputed))\\nprint(len(G_T))\\nprint(len(imputed))\\nprint(type(G_T[0]))\\nprint(len(G_T[0]))\\nprint(type(imputed[0]))\\nprint(len(imputed[0]))\\n\\n#print(G_T[0])\\n#print(G_T)\\nprint(\"xxxxxxxxxxxxxxxxxxxxxx\")'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###TEST CELL###\n",
    "'''\n",
    "print(type(G_T))\n",
    "print(type(imputed))\n",
    "print(len(G_T))\n",
    "print(len(imputed))\n",
    "print(type(G_T[0]))\n",
    "print(len(G_T[0]))\n",
    "print(type(imputed[0]))\n",
    "print(len(imputed[0]))\n",
    "\n",
    "#print(G_T[0])\n",
    "#print(G_T)\n",
    "print(\"xxxxxxxxxxxxxxxxxxxxxx\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b3fdfea6-1440-4a84-97c9-f6f2403d3e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(groundTruth, predictedData):\n",
    "    num_ground_truth = len(groundTruth)\n",
    "    num_predicted_data = len(predictedData)\n",
    "    num_imputations_per_set = num_predicted_data // num_ground_truth\n",
    "    \n",
    "    accuracy_results_df = []\n",
    "    accuracy_results_col = []\n",
    "    \n",
    "    for i in range(num_ground_truth):\n",
    "        start_index = i * num_imputations_per_set\n",
    "        end_index = start_index + num_imputations_per_set\n",
    "\n",
    "        # flatten ground truth for ground truth df\n",
    "        gt_df = groundTruth[i]\n",
    "        \n",
    "        gt_df_Series = pd.Series()\n",
    "        for col in gt_df.columns:\n",
    "            gt_df_Series = pd.concat([gt_df_Series, gt_df[col].dropna()])\n",
    "        gt_df_Series = gt_df_Series.reset_index(drop=True)\n",
    "\n",
    "        # flatten ground truth for each column \n",
    "        gt_col_Series = []\n",
    "        for col in gt_df.columns:\n",
    "            series = gt_df[col]\n",
    "            series = series.dropna()\n",
    "            series = series.reset_index(drop=True)\n",
    "            gt_col_Series.append(pd.Series(series))\n",
    "        \n",
    "        for j in range(start_index, end_index):\n",
    "            pd_df = predictedData[j] # Get the predicted data for this imputation\n",
    "        \n",
    "            pd_df_Series = pd.Series()\n",
    "            for col in pd_df.columns:\n",
    "                pd_df_Series = pd.concat([pd_df_Series, pd_df[col].dropna()])\n",
    "            pd_df_Series = pd_df_Series.reset_index(drop=True)\n",
    "\n",
    "            # flatten ground truth for each column \n",
    "            pd_col_Series = []\n",
    "            for col in pd_df.columns:\n",
    "                series = pd_df[col]\n",
    "                series = series.dropna()\n",
    "                series = series.reset_index(drop=True)\n",
    "                pd_col_Series.append(pd.Series(series))\n",
    "\n",
    "            # Calculate metrics at the df level\n",
    "            accuracyPercent_df = np.round((gt_df_Series - pd_df_Series) / gt_df_Series * 100)\n",
    "            mean_accuracy_df = np.round(np.mean(accuracyPercent_df), 2)\n",
    "            stdev_accuracy_df = np.round(np.std(accuracyPercent_df), 2)\n",
    "            var_df = np.round(predictedData[j].var(), 2)\n",
    "            mse_df = np.round(mean_squared_error(gt_df_Series, pd_df_Series, squared=False), 2)\n",
    "            \n",
    "            accuracy_results_df.append((accuracyPercent_df, mean_accuracy_df, \n",
    "                                     stdev_accuracy_df, var_df, mse_df))\n",
    "\n",
    "            # Calculate metrics at the col level\n",
    "            for A, B in zip(gt_col_Series, pd_col_Series):\n",
    "                    accuracyPercent_col = np.round((A - B) / A * 100)\n",
    "                    mean_accuracy_col = np.round(np.mean(accuracyPercent_col), 2)\n",
    "                    stdev_accuracy_col = np.round(np.std(accuracyPercent_col), 2)\n",
    "                    var_col = np.round(B.var(), 2)\n",
    "                    mse_col = np.round(mean_squared_error(A, B, squared=False), 2)\n",
    "                    \n",
    "                    accuracy_results_col.append((accuracyPercent_col, mean_accuracy_col,\n",
    "                                            stdev_accuracy_col, var_col, mse_col))\n",
    "    \n",
    "    print(\"accuracy results cell by cell for df \\n\", \"accuracy % across df:\", mean_accuracy_df, \"\\n\",\n",
    "          \"stdev across df:\", stdev_accuracy_df, \"\\n\", \"variance across df:\", var_df, \"\\n\",\n",
    "          \"mse across df:\", mse_df, \"\\n\", \"accuracy results cell by cell for columns \\n\", \"accuracy % across column:\",\n",
    "          mean_accuracy_col, \"\\n\", \"stdev across column:\", stdev_accuracy_col, \"\\n\", \"variance across col:\",\n",
    "          var_col, \"\\n\", \"mse across column:\", mse_col)\n",
    "    \n",
    "    return accuracy_results_df, accuracy_results_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0cef1d9a-fc30-44cb-999c-ba13c55d6ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy results cell by cell for df \n",
      " accuracy % across df: -0.2 \n",
      " stdev across df: 4.3 \n",
      " variance across df: Length    0.50\n",
      "Width     0.16\n",
      "Height    0.01\n",
      "dtype: float64 \n",
      " mse across df: 2.5 \n",
      " accuracy results cell by cell for columns \n",
      " accuracy % across column: -0.25 \n",
      " stdev across column: 4.98 \n",
      " variance across col: 0.01 \n",
      " mse across column: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\J\\AppData\\Local\\Temp\\ipykernel_33892\\4028562387.py:18: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  gt_df_Series = pd.concat([gt_df_Series, gt_df[col].dropna()])\n",
      "C:\\Users\\J\\AppData\\Local\\Temp\\ipykernel_33892\\4028562387.py:34: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  pd_df_Series = pd.concat([pd_df_Series, pd_df[col].dropna()])\n",
      "C:\\Users\\J\\AppData\\Local\\Temp\\ipykernel_33892\\4028562387.py:34: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  pd_df_Series = pd.concat([pd_df_Series, pd_df[col].dropna()])\n",
      "C:\\Users\\J\\AppData\\Local\\Temp\\ipykernel_33892\\4028562387.py:34: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  pd_df_Series = pd.concat([pd_df_Series, pd_df[col].dropna()])\n",
      "C:\\Users\\J\\AppData\\Local\\Temp\\ipykernel_33892\\4028562387.py:18: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  gt_df_Series = pd.concat([gt_df_Series, gt_df[col].dropna()])\n",
      "C:\\Users\\J\\AppData\\Local\\Temp\\ipykernel_33892\\4028562387.py:34: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  pd_df_Series = pd.concat([pd_df_Series, pd_df[col].dropna()])\n",
      "C:\\Users\\J\\AppData\\Local\\Temp\\ipykernel_33892\\4028562387.py:34: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  pd_df_Series = pd.concat([pd_df_Series, pd_df[col].dropna()])\n",
      "C:\\Users\\J\\AppData\\Local\\Temp\\ipykernel_33892\\4028562387.py:34: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  pd_df_Series = pd.concat([pd_df_Series, pd_df[col].dropna()])\n",
      "C:\\Users\\J\\AppData\\Local\\Temp\\ipykernel_33892\\4028562387.py:18: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  gt_df_Series = pd.concat([gt_df_Series, gt_df[col].dropna()])\n",
      "C:\\Users\\J\\AppData\\Local\\Temp\\ipykernel_33892\\4028562387.py:34: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  pd_df_Series = pd.concat([pd_df_Series, pd_df[col].dropna()])\n",
      "C:\\Users\\J\\AppData\\Local\\Temp\\ipykernel_33892\\4028562387.py:34: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  pd_df_Series = pd.concat([pd_df_Series, pd_df[col].dropna()])\n",
      "C:\\Users\\J\\AppData\\Local\\Temp\\ipykernel_33892\\4028562387.py:34: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  pd_df_Series = pd.concat([pd_df_Series, pd_df[col].dropna()])\n",
      "C:\\Users\\J\\AppData\\Local\\Temp\\ipykernel_33892\\4028562387.py:18: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  gt_df_Series = pd.concat([gt_df_Series, gt_df[col].dropna()])\n",
      "C:\\Users\\J\\AppData\\Local\\Temp\\ipykernel_33892\\4028562387.py:34: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  pd_df_Series = pd.concat([pd_df_Series, pd_df[col].dropna()])\n",
      "C:\\Users\\J\\AppData\\Local\\Temp\\ipykernel_33892\\4028562387.py:34: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  pd_df_Series = pd.concat([pd_df_Series, pd_df[col].dropna()])\n",
      "C:\\Users\\J\\AppData\\Local\\Temp\\ipykernel_33892\\4028562387.py:34: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  pd_df_Series = pd.concat([pd_df_Series, pd_df[col].dropna()])\n",
      "C:\\Users\\J\\AppData\\Local\\Temp\\ipykernel_33892\\4028562387.py:18: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  gt_df_Series = pd.concat([gt_df_Series, gt_df[col].dropna()])\n",
      "C:\\Users\\J\\AppData\\Local\\Temp\\ipykernel_33892\\4028562387.py:34: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  pd_df_Series = pd.concat([pd_df_Series, pd_df[col].dropna()])\n",
      "C:\\Users\\J\\AppData\\Local\\Temp\\ipykernel_33892\\4028562387.py:34: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  pd_df_Series = pd.concat([pd_df_Series, pd_df[col].dropna()])\n",
      "C:\\Users\\J\\AppData\\Local\\Temp\\ipykernel_33892\\4028562387.py:34: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  pd_df_Series = pd.concat([pd_df_Series, pd_df[col].dropna()])\n",
      "C:\\Users\\J\\AppData\\Local\\Temp\\ipykernel_33892\\4028562387.py:18: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  gt_df_Series = pd.concat([gt_df_Series, gt_df[col].dropna()])\n",
      "C:\\Users\\J\\AppData\\Local\\Temp\\ipykernel_33892\\4028562387.py:34: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  pd_df_Series = pd.concat([pd_df_Series, pd_df[col].dropna()])\n",
      "C:\\Users\\J\\AppData\\Local\\Temp\\ipykernel_33892\\4028562387.py:34: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  pd_df_Series = pd.concat([pd_df_Series, pd_df[col].dropna()])\n",
      "C:\\Users\\J\\AppData\\Local\\Temp\\ipykernel_33892\\4028562387.py:34: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  pd_df_Series = pd.concat([pd_df_Series, pd_df[col].dropna()])\n"
     ]
    }
   ],
   "source": [
    "x = accuracy(GT, imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a3db43b5-999e-447d-9d0d-f2869a9bd3af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(type(x))\\nprint(len(x))\\nprint(type(x[0]))\\nprint(len(x[0]))\\nprint(x[1][3])'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###TEST CELL###\n",
    "'''\n",
    "print(type(x))\n",
    "print(len(x))\n",
    "print(type(x[0]))\n",
    "print(len(x[0]))\n",
    "print(x[1][3])'''    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6aaf4074-9553-41d5-b714-019a422afff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_df_accuracy_list(df_list):\n",
    "    # Create a list of tuples containing the 'mean_accuracy' values and their corresponding indices\n",
    "    accuracy_indices = [(i, abs(results[1])) for i, results in enumerate(df_list)]\n",
    "    \n",
    "    # Sort the list of tuples by 'mean_accuracy' values in descending order\n",
    "    sorted_accuracy_indices = sorted(accuracy_indices, key=lambda x: x[1], reverse=False)\n",
    "    \n",
    "    return sorted_accuracy_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "49d9faca-a7bf-4916-b320-7e693f1cd65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x = x[0]\n",
    "s = max_df_accuracy_list(df_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2ca84bed-6e97-40f8-b32a-0673c97b4fd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(s)'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###TEST CELL###\n",
    "'''\n",
    "print(s)'''  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7fb78488-29d0-4e38-9c21-56ed2d57234a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 12\n",
      "stdev_thresh: 3\n",
      "missing_percent: 15\n",
      "iterations: 3\n"
     ]
    }
   ],
   "source": [
    "print_dict_without_dataframe(z, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b5e99c07-7a06-4d2b-a708-0d27cb1aa6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_stats(df, storage):\n",
    "    for col in df.columns:\n",
    "        summary = df[col].describe()\n",
    "        count = summary.loc['count']\n",
    "        mean = summary.loc['mean']\n",
    "        std_dev = summary.loc['std']\n",
    "        var = df[col].var()\n",
    "        storage.append((count, np.round(mean, 2), np.round(std_dev, 2), np.round(var, 2)))\n",
    "    print(\"Count, mean, std_dev, variance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "150d63ee-9bb8-47dc-8817-f0abf68bfb29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count, mean, std_dev, variance\n",
      "3\n",
      "[(455.0, 99.68, 4.17, 17.38), (455.0, 49.94, 2.15, 4.62), (455.0, 20.31, 1.06, 1.12)]\n"
     ]
    }
   ],
   "source": [
    "descript_stat_start = []\n",
    "start = df_nomissing.copy()\n",
    "df_stats(start, descript_stat_start)\n",
    "print(len(descript_stat_start))\n",
    "print(descript_stat_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2ecfa43a-42fe-4a79-a7c0-8e211a48b6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_list_stats(df_list, storage):\n",
    "    for df in df_list:\n",
    "        df_col = []\n",
    "        for col in df.columns:\n",
    "            summary = df[col].describe()\n",
    "            count = summary.loc['count']\n",
    "            mean = summary.loc['mean']\n",
    "            std_dev = summary.loc['std']\n",
    "            var = df[col].var()\n",
    "            df_col.append((count, np.round(mean, 2), np.round(std_dev, 2), np.round(var, 2)))\n",
    "        storage.append(df_col)\n",
    "    print(\"Count, mean, std_dev, variance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "8adb8eca-c805-466f-b225-55cf2e878838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count, mean, std_dev, variance\n",
      "2\n",
      "[(408.0, 99.15, 3.13, 9.81), (408.0, 49.87, 1.8, 3.24), (408.0, 20.25, 1.0, 1.0)]\n",
      "[(446.0, 99.46, 3.83, 14.7), (446.0, 49.91, 2.05, 4.2), (446.0, 20.28, 1.04, 1.08)]\n"
     ]
    }
   ],
   "source": [
    "sa = a.copy()\n",
    "descript_stat_noOuts = []\n",
    "df_list_stats(sa, descript_stat_noOuts)\n",
    "print(len(descript_stat_noOuts))\n",
    "print(descript_stat_noOuts[0])\n",
    "print(descript_stat_noOuts[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "019638fc-81b6-4b17-9f5c-e8c723906dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count, mean, std_dev, variance\n",
      "6\n",
      "[[(388.0, 99.11, 3.14, 9.86), (388.0, 49.88, 1.78, 3.18), (388.0, 20.27, 1.0, 1.0)], [(347.0, 99.21, 3.06, 9.39), (347.0, 49.89, 1.79, 3.22), (347.0, 20.23, 1.0, 1.0)], [(266.0, 99.11, 3.13, 9.81), (266.0, 49.89, 1.84, 3.4), (266.0, 20.23, 1.0, 1.0)], [(424.0, 99.48, 3.89, 15.11), (424.0, 49.9, 2.06, 4.26), (424.0, 20.26, 1.05, 1.1)]]\n"
     ]
    }
   ],
   "source": [
    "saa = aa[0].copy()\n",
    "descript_stat_missing = []\n",
    "df_list_stats(saa, descript_stat_missing)\n",
    "print(len(descript_stat_missing))\n",
    "print(descript_stat_missing[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "e13c0b41-8300-4f90-9ba6-712c714e30d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count, mean, std_dev, variance\n",
      "18\n",
      "[[(408.0, 99.11, 3.06, 9.38), (408.0, 49.88, 1.74, 3.03), (408.0, 20.27, 0.97, 0.95)], [(408.0, 99.11, 3.06, 9.38), (408.0, 49.88, 1.74, 3.03), (408.0, 20.27, 0.97, 0.95)], [(408.0, 99.11, 3.06, 9.38), (408.0, 49.88, 1.74, 3.03), (408.0, 20.27, 0.97, 0.95)], [(408.0, 99.21, 2.82, 7.98), (408.0, 49.89, 1.65, 2.74), (408.0, 20.23, 0.92, 0.85)], [(408.0, 99.21, 2.82, 7.98), (408.0, 49.89, 1.65, 2.74), (408.0, 20.23, 0.92, 0.85)]]\n"
     ]
    }
   ],
   "source": [
    "ssaa = w[0].copy()\n",
    "descript_stat_imputed = []\n",
    "df_list_stats(ssaa, descript_stat_imputed)\n",
    "print(len(descript_stat_imputed))\n",
    "print(descript_stat_imputed[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "1a488291-ecf0-4a23-a6a4-81532d69c1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "54\n",
      "(0.7, 2.63, 0.0, 2.96)\n"
     ]
    }
   ],
   "source": [
    "zx = x[0].copy()\n",
    "zzxx = x[1].copy()\n",
    "print(len(zx))\n",
    "print(len(zzxx))\n",
    "print(zzxx[0][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "31c446f3-a164-4cf0-9986-2ce8d1acd3db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0     3.0\n",
      "1    -8.0\n",
      "2    -8.0\n",
      "3     5.0\n",
      "4     0.0\n",
      "5     5.0\n",
      "6    -4.0\n",
      "7    -4.0\n",
      "8    -3.0\n",
      "9    -5.0\n",
      "10   -4.0\n",
      "11    2.0\n",
      "12    3.0\n",
      "13   -3.0\n",
      "14    5.0\n",
      "15   -3.0\n",
      "16    3.0\n",
      "17    4.0\n",
      "18   -1.0\n",
      "19   -2.0\n",
      "Name: Width, dtype: float64, -0.75, 4.15, 0.0, 2.07), (0     -3.0\n",
      "1     -0.0\n",
      "2     -4.0\n",
      "3      2.0\n",
      "4     -2.0\n",
      "5      5.0\n",
      "6      1.0\n",
      "7     -7.0\n",
      "8     -1.0\n",
      "9     -9.0\n",
      "10    -3.0\n",
      "11    -8.0\n",
      "12    -3.0\n",
      "13    -1.0\n",
      "14    -6.0\n",
      "15     6.0\n",
      "16    -9.0\n",
      "17   -10.0\n",
      "18     2.0\n",
      "19    -0.0\n",
      "Name: Height, dtype: float64, -2.5, 4.5, 0.0, 0.99), (0     5.0\n",
      "1    -1.0\n",
      "2     2.0\n",
      "3     2.0\n",
      "4    -2.0\n",
      "5     1.0\n",
      "6     4.0\n",
      "7     1.0\n",
      "8    -3.0\n",
      "9     4.0\n",
      "10    4.0\n",
      "11    3.0\n",
      "12   -1.0\n",
      "13    3.0\n",
      "14   -2.0\n",
      "15    0.0\n",
      "16    2.0\n",
      "17   -4.0\n",
      "18   -2.0\n",
      "19   -2.0\n",
      "Name: Length, dtype: float64, 0.7, 2.63, 0.0, 2.96), (0     3.0\n",
      "1    -8.0\n",
      "2    -8.0\n",
      "3     5.0\n",
      "4     0.0\n",
      "5     5.0\n",
      "6    -4.0\n",
      "7    -4.0\n",
      "8    -3.0\n",
      "9    -5.0\n",
      "10   -4.0\n",
      "11    2.0\n",
      "12    3.0\n",
      "13   -3.0\n",
      "14    5.0\n",
      "15   -3.0\n",
      "16    3.0\n",
      "17    4.0\n",
      "18   -1.0\n",
      "19   -2.0\n",
      "Name: Width, dtype: float64, -0.75, 4.15, 0.0, 2.07), (0     -3.0\n",
      "1     -0.0\n",
      "2     -4.0\n",
      "3      2.0\n",
      "4     -2.0\n",
      "5      5.0\n",
      "6      1.0\n",
      "7     -7.0\n",
      "8     -1.0\n",
      "9     -9.0\n",
      "10    -3.0\n",
      "11    -8.0\n",
      "12    -3.0\n",
      "13    -1.0\n",
      "14    -6.0\n",
      "15     6.0\n",
      "16    -9.0\n",
      "17   -10.0\n",
      "18     2.0\n",
      "19    -0.0\n",
      "Name: Height, dtype: float64, -2.5, 4.5, 0.0, 0.99), (0     5.0\n",
      "1    -1.0\n",
      "2     2.0\n",
      "3     2.0\n",
      "4    -2.0\n",
      "5     1.0\n",
      "6     4.0\n",
      "7     1.0\n",
      "8    -3.0\n",
      "9     4.0\n",
      "10    4.0\n",
      "11    3.0\n",
      "12   -1.0\n",
      "13    3.0\n",
      "14   -2.0\n",
      "15    0.0\n",
      "16    2.0\n",
      "17   -4.0\n",
      "18   -2.0\n",
      "19   -2.0\n",
      "Name: Length, dtype: float64, 0.7, 2.63, 0.0, 2.96), (0     3.0\n",
      "1    -8.0\n",
      "2    -8.0\n",
      "3     5.0\n",
      "4     0.0\n",
      "5     5.0\n",
      "6    -4.0\n",
      "7    -4.0\n",
      "8    -3.0\n",
      "9    -5.0\n",
      "10   -4.0\n",
      "11    2.0\n",
      "12    3.0\n",
      "13   -3.0\n",
      "14    5.0\n",
      "15   -3.0\n",
      "16    3.0\n",
      "17    4.0\n",
      "18   -1.0\n",
      "19   -2.0\n",
      "Name: Width, dtype: float64, -0.75, 4.15, 0.0, 2.07), (0     -3.0\n",
      "1     -0.0\n",
      "2     -4.0\n",
      "3      2.0\n",
      "4     -2.0\n",
      "5      5.0\n",
      "6      1.0\n",
      "7     -7.0\n",
      "8     -1.0\n",
      "9     -9.0\n",
      "10    -3.0\n",
      "11    -8.0\n",
      "12    -3.0\n",
      "13    -1.0\n",
      "14    -6.0\n",
      "15     6.0\n",
      "16    -9.0\n",
      "17   -10.0\n",
      "18     2.0\n",
      "19    -0.0\n",
      "Name: Height, dtype: float64, -2.5, 4.5, 0.0, 0.99), (0     7.0\n",
      "1     5.0\n",
      "2     8.0\n",
      "3    -1.0\n",
      "4     6.0\n",
      "     ... \n",
      "56   -2.0\n",
      "57   -4.0\n",
      "58    2.0\n",
      "59    2.0\n",
      "60    4.0\n",
      "Name: Length, Length: 61, dtype: float64, -0.48, 3.43, 0.0, 3.5), (0    -1.0\n",
      "1    -4.0\n",
      "2    -3.0\n",
      "3    -2.0\n",
      "4     7.0\n",
      "     ... \n",
      "56   -6.0\n",
      "57    3.0\n",
      "58    3.0\n",
      "59   -1.0\n",
      "60    2.0\n",
      "Name: Width, Length: 61, dtype: float64, -0.38, 3.72, 0.0, 1.83), (0     6.0\n",
      "1    -5.0\n",
      "2    -1.0\n",
      "3    -0.0\n",
      "4    -8.0\n",
      "     ... \n",
      "56    3.0\n",
      "57    8.0\n",
      "58    4.0\n",
      "59    3.0\n",
      "60    6.0\n",
      "Name: Height, Length: 61, dtype: float64, 0.49, 4.9, 0.0, 1.0), (0     7.0\n",
      "1     5.0\n",
      "2     8.0\n",
      "3    -1.0\n",
      "4     6.0\n",
      "     ... \n",
      "56   -2.0\n",
      "57   -4.0\n",
      "58    2.0\n",
      "59    2.0\n",
      "60    4.0\n",
      "Name: Length, Length: 61, dtype: float64, -0.48, 3.43, 0.0, 3.5), (0    -1.0\n",
      "1    -4.0\n",
      "2    -3.0\n",
      "3    -2.0\n",
      "4     7.0\n",
      "     ... \n",
      "56   -6.0\n",
      "57    3.0\n",
      "58    3.0\n",
      "59   -1.0\n",
      "60    2.0\n",
      "Name: Width, Length: 61, dtype: float64, -0.38, 3.72, 0.0, 1.83), (0     6.0\n",
      "1    -5.0\n",
      "2    -1.0\n",
      "3    -0.0\n",
      "4    -8.0\n",
      "     ... \n",
      "56    3.0\n",
      "57    8.0\n",
      "58    4.0\n",
      "59    3.0\n",
      "60    6.0\n",
      "Name: Height, Length: 61, dtype: float64, 0.49, 4.9, 0.0, 1.0), (0     7.0\n",
      "1     5.0\n",
      "2     8.0\n",
      "3    -1.0\n",
      "4     6.0\n",
      "     ... \n",
      "56   -2.0\n",
      "57   -4.0\n",
      "58    2.0\n",
      "59    2.0\n",
      "60    4.0\n",
      "Name: Length, Length: 61, dtype: float64, -0.48, 3.43, 0.0, 3.5), (0    -1.0\n",
      "1    -4.0\n",
      "2    -3.0\n",
      "3    -2.0\n",
      "4     7.0\n",
      "     ... \n",
      "56   -6.0\n",
      "57    3.0\n",
      "58    3.0\n",
      "59   -1.0\n",
      "60    2.0\n",
      "Name: Width, Length: 61, dtype: float64, -0.38, 3.72, 0.0, 1.83), (0     6.0\n",
      "1    -5.0\n",
      "2    -1.0\n",
      "3    -0.0\n",
      "4    -8.0\n",
      "     ... \n",
      "56    3.0\n",
      "57    8.0\n",
      "58    4.0\n",
      "59    3.0\n",
      "60    6.0\n",
      "Name: Height, Length: 61, dtype: float64, 0.49, 4.9, 0.0, 1.0), (0      4.0\n",
      "1      7.0\n",
      "2     -4.0\n",
      "3     -2.0\n",
      "4      3.0\n",
      "      ... \n",
      "137    2.0\n",
      "138    1.0\n",
      "139   -1.0\n",
      "140   -1.0\n",
      "141   -5.0\n",
      "Name: Length, Length: 142, dtype: float64, 0.0, 3.12, 0.14, 3.13), (0      3.0\n",
      "1      4.0\n",
      "2     -1.0\n",
      "3     -1.0\n",
      "4     -4.0\n",
      "      ... \n",
      "137   -2.0\n",
      "138    4.0\n",
      "139    3.0\n",
      "140   -4.0\n",
      "141    2.0\n",
      "Name: Width, Length: 142, dtype: float64, -0.3, 3.49, 0.07, 1.73), (0     -3.0\n",
      "1      6.0\n",
      "2     -4.0\n",
      "3     -5.0\n",
      "4     -1.0\n",
      "      ... \n",
      "137   -4.0\n",
      "138   -3.0\n",
      "139    5.0\n",
      "140   -3.0\n",
      "141    6.0\n",
      "Name: Height, Length: 142, dtype: float64, 0.1, 4.97, 0.0, 0.99), (0      4.0\n",
      "1      7.0\n",
      "2     -4.0\n",
      "3     -2.0\n",
      "4      3.0\n",
      "      ... \n",
      "137    2.0\n",
      "138    0.0\n",
      "139   -1.0\n",
      "140   -1.0\n",
      "141   -5.0\n",
      "Name: Length, Length: 142, dtype: float64, 0.02, 3.13, 0.24, 3.13), (0      3.0\n",
      "1      4.0\n",
      "2     -1.0\n",
      "3     -1.0\n",
      "4     -4.0\n",
      "      ... \n",
      "137   -2.0\n",
      "138    4.0\n",
      "139    3.0\n",
      "140   -4.0\n",
      "141    2.0\n",
      "Name: Width, Length: 142, dtype: float64, -0.3, 3.48, 0.1, 1.74), (0     -3.0\n",
      "1      6.0\n",
      "2     -4.0\n",
      "3     -5.0\n",
      "4     -1.0\n",
      "      ... \n",
      "137   -4.0\n",
      "138   -3.0\n",
      "139    5.0\n",
      "140   -3.0\n",
      "141    6.0\n",
      "Name: Height, Length: 142, dtype: float64, 0.13, 4.96, 0.0, 0.99), (0      4.0\n",
      "1      7.0\n",
      "2     -4.0\n",
      "3     -2.0\n",
      "4      3.0\n",
      "      ... \n",
      "137    2.0\n",
      "138    0.0\n",
      "139   -1.0\n",
      "140   -1.0\n",
      "141   -5.0\n",
      "Name: Length, Length: 142, dtype: float64, 0.02, 3.13, 0.24, 3.13), (0      3.0\n",
      "1      4.0\n",
      "2     -1.0\n",
      "3     -1.0\n",
      "4     -4.0\n",
      "      ... \n",
      "137   -2.0\n",
      "138    4.0\n",
      "139    3.0\n",
      "140   -4.0\n",
      "141    2.0\n",
      "Name: Width, Length: 142, dtype: float64, -0.3, 3.48, 0.1, 1.74), (0     -3.0\n",
      "1      6.0\n",
      "2     -4.0\n",
      "3     -5.0\n",
      "4     -1.0\n",
      "      ... \n",
      "137   -4.0\n",
      "138   -3.0\n",
      "139    5.0\n",
      "140   -3.0\n",
      "141    6.0\n",
      "Name: Height, Length: 142, dtype: float64, 0.13, 4.96, 0.0, 0.99), (0    -1.0\n",
      "1     2.0\n",
      "2     1.0\n",
      "3    -3.0\n",
      "4    -1.0\n",
      "5     2.0\n",
      "6    -6.0\n",
      "7    -3.0\n",
      "8     2.0\n",
      "9     2.0\n",
      "10   -2.0\n",
      "11   -4.0\n",
      "12    0.0\n",
      "13   -1.0\n",
      "14   -5.0\n",
      "15    5.0\n",
      "16    2.0\n",
      "17    2.0\n",
      "18   -0.0\n",
      "19   -2.0\n",
      "20   -1.0\n",
      "21    1.0\n",
      "Name: Length, dtype: float64, -0.45, 2.64, 0.51, 2.61), (0    -1.0\n",
      "1     5.0\n",
      "2     3.0\n",
      "3     2.0\n",
      "4    -0.0\n",
      "5     3.0\n",
      "6     4.0\n",
      "7    -4.0\n",
      "8     4.0\n",
      "9    -5.0\n",
      "10   -6.0\n",
      "11   -4.0\n",
      "12   -2.0\n",
      "13   -2.0\n",
      "14   -1.0\n",
      "15    4.0\n",
      "16   -6.0\n",
      "17    2.0\n",
      "18   -4.0\n",
      "19    6.0\n",
      "20    3.0\n",
      "21    3.0\n",
      "Name: Width, dtype: float64, 0.18, 3.74, 0.24, 1.87), (0     4.0\n",
      "1     1.0\n",
      "2     4.0\n",
      "3    -1.0\n",
      "4    -2.0\n",
      "5     6.0\n",
      "6    -4.0\n",
      "7     0.0\n",
      "8     3.0\n",
      "9     3.0\n",
      "10    5.0\n",
      "11   -0.0\n",
      "12    2.0\n",
      "13   -7.0\n",
      "14    4.0\n",
      "15    6.0\n",
      "16    7.0\n",
      "17    6.0\n",
      "18   -6.0\n",
      "19   -1.0\n",
      "20    7.0\n",
      "21    5.0\n",
      "Name: Height, dtype: float64, 1.91, 4.01, 0.01, 0.93), (0    -1.0\n",
      "1     2.0\n",
      "2     1.0\n",
      "3    -3.0\n",
      "4    -1.0\n",
      "5     2.0\n",
      "6    -6.0\n",
      "7    -3.0\n",
      "8     2.0\n",
      "9     2.0\n",
      "10   -2.0\n",
      "11   -4.0\n",
      "12    0.0\n",
      "13   -1.0\n",
      "14   -5.0\n",
      "15    5.0\n",
      "16    2.0\n",
      "17    2.0\n",
      "18   -0.0\n",
      "19   -2.0\n",
      "20   -1.0\n",
      "21    1.0\n",
      "Name: Length, dtype: float64, -0.45, 2.64, 0.51, 2.61), (0    -1.0\n",
      "1     5.0\n",
      "2     3.0\n",
      "3     2.0\n",
      "4    -0.0\n",
      "5     3.0\n",
      "6     4.0\n",
      "7    -4.0\n",
      "8     4.0\n",
      "9    -5.0\n",
      "10   -6.0\n",
      "11   -4.0\n",
      "12   -2.0\n",
      "13   -2.0\n",
      "14   -1.0\n",
      "15    4.0\n",
      "16   -6.0\n",
      "17    2.0\n",
      "18   -4.0\n",
      "19    6.0\n",
      "20    3.0\n",
      "21    3.0\n",
      "Name: Width, dtype: float64, 0.18, 3.74, 0.24, 1.87), (0     4.0\n",
      "1     1.0\n",
      "2     4.0\n",
      "3    -1.0\n",
      "4    -2.0\n",
      "5     6.0\n",
      "6    -4.0\n",
      "7     0.0\n",
      "8     3.0\n",
      "9     3.0\n",
      "10    5.0\n",
      "11   -0.0\n",
      "12    2.0\n",
      "13   -7.0\n",
      "14    4.0\n",
      "15    6.0\n",
      "16    7.0\n",
      "17    6.0\n",
      "18   -6.0\n",
      "19   -1.0\n",
      "20    7.0\n",
      "21    5.0\n",
      "Name: Height, dtype: float64, 1.91, 4.01, 0.01, 0.93), (0    -1.0\n",
      "1     2.0\n",
      "2     1.0\n",
      "3    -3.0\n",
      "4    -1.0\n",
      "5     2.0\n",
      "6    -6.0\n",
      "7    -3.0\n",
      "8     2.0\n",
      "9     2.0\n",
      "10   -2.0\n",
      "11   -4.0\n",
      "12    0.0\n",
      "13   -1.0\n",
      "14   -5.0\n",
      "15    5.0\n",
      "16    2.0\n",
      "17    2.0\n",
      "18   -0.0\n",
      "19   -2.0\n",
      "20   -1.0\n",
      "21    1.0\n",
      "Name: Length, dtype: float64, -0.45, 2.64, 0.51, 2.61), (0    -1.0\n",
      "1     5.0\n",
      "2     3.0\n",
      "3     2.0\n",
      "4    -0.0\n",
      "5     3.0\n",
      "6     4.0\n",
      "7    -4.0\n",
      "8     4.0\n",
      "9    -5.0\n",
      "10   -6.0\n",
      "11   -4.0\n",
      "12   -2.0\n",
      "13   -2.0\n",
      "14   -1.0\n",
      "15    4.0\n",
      "16   -6.0\n",
      "17    2.0\n",
      "18   -4.0\n",
      "19    6.0\n",
      "20    3.0\n",
      "21    3.0\n",
      "Name: Width, dtype: float64, 0.18, 3.74, 0.24, 1.87), (0     4.0\n",
      "1     1.0\n",
      "2     4.0\n",
      "3    -1.0\n",
      "4    -2.0\n",
      "5     6.0\n",
      "6    -4.0\n",
      "7     0.0\n",
      "8     3.0\n",
      "9     3.0\n",
      "10    5.0\n",
      "11   -0.0\n",
      "12    2.0\n",
      "13   -7.0\n",
      "14    4.0\n",
      "15    6.0\n",
      "16    7.0\n",
      "17    6.0\n",
      "18   -6.0\n",
      "19   -1.0\n",
      "20    7.0\n",
      "21    5.0\n",
      "Name: Height, dtype: float64, 1.91, 4.01, 0.01, 0.93), (0     5.0\n",
      "1     5.0\n",
      "2     7.0\n",
      "3     5.0\n",
      "4    -3.0\n",
      "     ... \n",
      "61   -2.0\n",
      "62   -2.0\n",
      "63    2.0\n",
      "64    2.0\n",
      "65   -6.0\n",
      "Name: Length, Length: 66, dtype: float64, -0.95, 3.51, 0.37, 3.54), (0     -4.0\n",
      "1    -10.0\n",
      "2     -6.0\n",
      "3      9.0\n",
      "4      1.0\n",
      "      ... \n",
      "61    -1.0\n",
      "62     3.0\n",
      "63     3.0\n",
      "64     5.0\n",
      "65    -2.0\n",
      "Name: Width, Length: 66, dtype: float64, 0.52, 4.28, 0.07, 2.19), (0     0.0\n",
      "1    -2.0\n",
      "2     4.0\n",
      "3    -1.0\n",
      "4     0.0\n",
      "     ... \n",
      "61   -0.0\n",
      "62    4.0\n",
      "63    4.0\n",
      "64    1.0\n",
      "65    4.0\n",
      "Name: Height, Length: 66, dtype: float64, -0.15, 4.92, 0.01, 0.99), (0     5.0\n",
      "1     5.0\n",
      "2     7.0\n",
      "3     5.0\n",
      "4    -3.0\n",
      "     ... \n",
      "61   -2.0\n",
      "62   -2.0\n",
      "63    2.0\n",
      "64    2.0\n",
      "65   -6.0\n",
      "Name: Length, Length: 66, dtype: float64, -0.95, 3.51, 0.37, 3.54), (0     -4.0\n",
      "1    -10.0\n",
      "2     -6.0\n",
      "3      9.0\n",
      "4      1.0\n",
      "      ... \n",
      "61    -1.0\n",
      "62     3.0\n",
      "63     3.0\n",
      "64     5.0\n",
      "65    -2.0\n",
      "Name: Width, Length: 66, dtype: float64, 0.52, 4.28, 0.07, 2.19), (0     0.0\n",
      "1    -2.0\n",
      "2     4.0\n",
      "3    -1.0\n",
      "4     0.0\n",
      "     ... \n",
      "61   -0.0\n",
      "62    4.0\n",
      "63    4.0\n",
      "64    1.0\n",
      "65    4.0\n",
      "Name: Height, Length: 66, dtype: float64, -0.15, 4.92, 0.01, 0.99), (0     5.0\n",
      "1     5.0\n",
      "2     7.0\n",
      "3     5.0\n",
      "4    -3.0\n",
      "     ... \n",
      "61   -2.0\n",
      "62   -2.0\n",
      "63    2.0\n",
      "64    2.0\n",
      "65   -6.0\n",
      "Name: Length, Length: 66, dtype: float64, -0.95, 3.51, 0.37, 3.54), (0     -4.0\n",
      "1    -10.0\n",
      "2     -6.0\n",
      "3      9.0\n",
      "4      1.0\n",
      "      ... \n",
      "61    -1.0\n",
      "62     3.0\n",
      "63     3.0\n",
      "64     5.0\n",
      "65    -2.0\n",
      "Name: Width, Length: 66, dtype: float64, 0.52, 4.28, 0.07, 2.19), (0     0.0\n",
      "1    -2.0\n",
      "2     4.0\n",
      "3    -1.0\n",
      "4     0.0\n",
      "     ... \n",
      "61   -0.0\n",
      "62    4.0\n",
      "63    4.0\n",
      "64    1.0\n",
      "65    4.0\n",
      "Name: Height, Length: 66, dtype: float64, -0.15, 4.92, 0.01, 0.99), (0       5.0\n",
      "1       1.0\n",
      "2     -11.0\n",
      "3       8.0\n",
      "4      -5.0\n",
      "       ... \n",
      "151     2.0\n",
      "152     3.0\n",
      "153    -1.0\n",
      "154    -1.0\n",
      "155     3.0\n",
      "Name: Length, Length: 156, dtype: float64, -0.58, 3.68, 0.34, 3.7), (0     -1.0\n",
      "1     -1.0\n",
      "2     -4.0\n",
      "3     -7.0\n",
      "4      2.0\n",
      "      ... \n",
      "151    3.0\n",
      "152    2.0\n",
      "153    5.0\n",
      "154   -3.0\n",
      "155    3.0\n",
      "Name: Width, Length: 156, dtype: float64, 0.26, 4.06, 0.13, 2.01), (0      7.0\n",
      "1     -4.0\n",
      "2      0.0\n",
      "3      4.0\n",
      "4     -3.0\n",
      "      ... \n",
      "151    1.0\n",
      "152   -7.0\n",
      "153   -7.0\n",
      "154   -5.0\n",
      "155    6.0\n",
      "Name: Height, Length: 156, dtype: float64, -0.26, 4.98, 0.01, 1.0), (0       5.0\n",
      "1       2.0\n",
      "2     -11.0\n",
      "3       8.0\n",
      "4      -5.0\n",
      "       ... \n",
      "151     2.0\n",
      "152     3.0\n",
      "153    -1.0\n",
      "154    -1.0\n",
      "155     3.0\n",
      "Name: Length, Length: 156, dtype: float64, -0.6, 3.71, 0.49, 3.7), (0     -1.0\n",
      "1     -1.0\n",
      "2     -4.0\n",
      "3     -7.0\n",
      "4      2.0\n",
      "      ... \n",
      "151    3.0\n",
      "152    3.0\n",
      "153    5.0\n",
      "154   -3.0\n",
      "155    3.0\n",
      "Name: Width, Length: 156, dtype: float64, 0.25, 4.05, 0.16, 2.01), (0      7.0\n",
      "1     -4.0\n",
      "2      0.0\n",
      "3      4.0\n",
      "4     -3.0\n",
      "      ... \n",
      "151    1.0\n",
      "152   -7.0\n",
      "153   -8.0\n",
      "154   -5.0\n",
      "155    6.0\n",
      "Name: Height, Length: 156, dtype: float64, -0.26, 4.97, 0.01, 1.0), (0       5.0\n",
      "1       2.0\n",
      "2     -11.0\n",
      "3       8.0\n",
      "4      -5.0\n",
      "       ... \n",
      "151     2.0\n",
      "152     3.0\n",
      "153    -1.0\n",
      "154    -1.0\n",
      "155     3.0\n",
      "Name: Length, Length: 156, dtype: float64, -0.61, 3.71, 0.5, 3.7), (0     -1.0\n",
      "1     -1.0\n",
      "2     -4.0\n",
      "3     -7.0\n",
      "4      2.0\n",
      "      ... \n",
      "151    3.0\n",
      "152    3.0\n",
      "153    5.0\n",
      "154   -3.0\n",
      "155    3.0\n",
      "Name: Width, Length: 156, dtype: float64, 0.26, 4.07, 0.16, 2.01), (0      7.0\n",
      "1     -4.0\n",
      "2      0.0\n",
      "3      4.0\n",
      "4     -3.0\n",
      "      ... \n",
      "151    1.0\n",
      "152   -7.0\n",
      "153   -8.0\n",
      "154   -5.0\n",
      "155    6.0\n",
      "Name: Height, Length: 156, dtype: float64, -0.25, 4.98, 0.01, 1.0)]\n"
     ]
    }
   ],
   "source": [
    "print(zzxx[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "45472731-b35b-4170-b14f-11ec83edaece",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_stat_extract(df, storage):\n",
    "    df_L = []\n",
    "    df_W = []\n",
    "    df_H = []\n",
    "    for i in range(len(df)):\n",
    "\n",
    "        if i % 3 == 0:\n",
    "            df_L.append(df[i][1:])\n",
    "        elif i % 3 == 1:\n",
    "            df_W.append(df[i][1:])\n",
    "        elif i % 3 == 2:\n",
    "            df_H.append(df[i][1:])\n",
    "\n",
    "    for L, W, H in zip(df_L, df_W, df_H):\n",
    "        storage.append((L, W, H))\n",
    "    print(\"mean, std_dev, variance, mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "34afa7cc-7131-4d97-befb-2aeab426f350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean, std_dev, variance, mse\n",
      "18\n",
      "((0.7, 2.63, 0.0, 2.96), (-0.75, 4.15, 0.0, 2.07), (-2.5, 4.5, 0.0, 0.99))\n",
      "3\n",
      "0.7\n",
      "2.63\n",
      "0.0\n",
      "2.96\n",
      "[((0.7, 2.63, 0.0, 2.96), (-0.75, 4.15, 0.0, 2.07), (-2.5, 4.5, 0.0, 0.99)), ((0.7, 2.63, 0.0, 2.96), (-0.75, 4.15, 0.0, 2.07), (-2.5, 4.5, 0.0, 0.99)), ((0.7, 2.63, 0.0, 2.96), (-0.75, 4.15, 0.0, 2.07), (-2.5, 4.5, 0.0, 0.99)), ((-0.48, 3.43, 0.0, 3.5), (-0.38, 3.72, 0.0, 1.83), (0.49, 4.9, 0.0, 1.0)), ((-0.48, 3.43, 0.0, 3.5), (-0.38, 3.72, 0.0, 1.83), (0.49, 4.9, 0.0, 1.0)), ((-0.48, 3.43, 0.0, 3.5), (-0.38, 3.72, 0.0, 1.83), (0.49, 4.9, 0.0, 1.0)), ((0.0, 3.12, 0.14, 3.13), (-0.3, 3.49, 0.07, 1.73), (0.1, 4.97, 0.0, 0.99)), ((0.02, 3.13, 0.24, 3.13), (-0.3, 3.48, 0.1, 1.74), (0.13, 4.96, 0.0, 0.99)), ((0.02, 3.13, 0.24, 3.13), (-0.3, 3.48, 0.1, 1.74), (0.13, 4.96, 0.0, 0.99)), ((-0.45, 2.64, 0.51, 2.61), (0.18, 3.74, 0.24, 1.87), (1.91, 4.01, 0.01, 0.93)), ((-0.45, 2.64, 0.51, 2.61), (0.18, 3.74, 0.24, 1.87), (1.91, 4.01, 0.01, 0.93)), ((-0.45, 2.64, 0.51, 2.61), (0.18, 3.74, 0.24, 1.87), (1.91, 4.01, 0.01, 0.93)), ((-0.95, 3.51, 0.37, 3.54), (0.52, 4.28, 0.07, 2.19), (-0.15, 4.92, 0.01, 0.99)), ((-0.95, 3.51, 0.37, 3.54), (0.52, 4.28, 0.07, 2.19), (-0.15, 4.92, 0.01, 0.99)), ((-0.95, 3.51, 0.37, 3.54), (0.52, 4.28, 0.07, 2.19), (-0.15, 4.92, 0.01, 0.99)), ((-0.58, 3.68, 0.34, 3.7), (0.26, 4.06, 0.13, 2.01), (-0.26, 4.98, 0.01, 1.0)), ((-0.6, 3.71, 0.49, 3.7), (0.25, 4.05, 0.16, 2.01), (-0.26, 4.97, 0.01, 1.0)), ((-0.61, 3.71, 0.5, 3.7), (0.26, 4.07, 0.16, 2.01), (-0.25, 4.98, 0.01, 1.0))]\n"
     ]
    }
   ],
   "source": [
    "mice_accuracy_descript_stats = []\n",
    "#zzxx = x[1].copy()\n",
    "acc_stat_extract(zzxx, mice_accuracy_descript_stats)\n",
    "print(len(mice_accuracy_descript_stats))\n",
    "print(mice_accuracy_descript_stats[0:18][0])\n",
    "v = len(mice_accuracy_descript_stats[0:18][0])\n",
    "print(v)\n",
    "for element in mice_accuracy_descript_stats[:][0][0]:\n",
    "    print(element)\n",
    "print(mice_accuracy_descript_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "6b092fbe-df0b-4819-bd48-42701cb5f091",
   "metadata": {},
   "outputs": [],
   "source": [
    "mice_mean_L = []\n",
    "mice_mean_W = []\n",
    "mice_mean_H = []\n",
    "mice_std_L = []\n",
    "mice_std_W = []\n",
    "mice_std_H = []\n",
    "mice_var_L = []\n",
    "mice_var_W = []\n",
    "mice_var_H = []\n",
    "mice_mse_L = []\n",
    "mice_mse_W = []\n",
    "mice_mse_H = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "d9ee5a7f-9134-4c8b-aa8d-ae6a10dc913d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tup in cc:\n",
    "    for j in range(len(tup[0])):       \n",
    "        if j == 0:\n",
    "            mice_mean_L.append(tup[0][j])\n",
    "        elif j == 1:\n",
    "            mice_std_L.append(tup[0][j])\n",
    "        elif j == 2:\n",
    "            mice_var_L.append(tup[0][j])\n",
    "        elif j == 3:\n",
    "            mice_mse_L.append(tup[0][j])\n",
    "\n",
    "for tup in cc:\n",
    "    for j in range(len(tup[1])):       \n",
    "        if j == 0:\n",
    "            mice_mean_W.append(tup[1][j])\n",
    "        elif j == 1:\n",
    "            mice_std_W.append(tup[1][j])\n",
    "        elif j == 2:\n",
    "            mice_var_W.append(tup[1][j])\n",
    "        elif j == 3:\n",
    "            mice_mse_W.append(tup[1][j])\n",
    "\n",
    "for tup in cc:\n",
    "    for j in range(len(tup[2])):       \n",
    "        if j == 0:\n",
    "            mice_mean_H.append(tup[2][j])\n",
    "        elif j == 1:\n",
    "            mice_std_H.append(tup[2][j])\n",
    "        elif j == 2:\n",
    "            mice_var_H.append(tup[2][j])\n",
    "        elif j == 3:\n",
    "            mice_mse_H.append(tup[2][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "442554b4-a71a-4b80-9fd4-585f374a0341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15fb675-6eca-408d-8640-0dc66ed14fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not sure about the couple of cells above this"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea97b8c3-6c43-42ea-b21d-1f78d9ef09a0",
   "metadata": {},
   "source": [
    "At this point I've run some stuff in R to generate some data about the starting datasets pre imputation and maybe analyze some of the python imputed? But I have at least 4 datasets imputed from R that are more Bayesian applications of MICE along with a RF. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "df200499-1483-4f7d-bb05-4dbca1bc9de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"C:\\\\Users\\\\J\\\\from_R\\\\pmm\"\n",
    "csv_pmm = [file for file in os.listdir(folder_path) if file.endswith(\".csv\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "14939b4c-7e83-4aad-9a4b-10276b61a1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pmm = []\n",
    "for file in csv_pmm:\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    df_pmm.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "e89be462-df77-42f6-9036-4695dc292cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "     Length  Width  Height\n",
      "0    102.67  49.53   19.69\n",
      "1    102.50  49.13   21.38\n",
      "2     95.37  52.25   21.51\n",
      "3     94.77  49.24   18.60\n",
      "4    104.26  47.90   19.46\n",
      "..      ...    ...     ...\n",
      "403   98.34  49.03   19.30\n",
      "404  101.24  52.50   20.96\n",
      "405   98.37  52.12   19.68\n",
      "406   94.16  48.39   21.60\n",
      "407  102.35  51.24   21.47\n",
      "\n",
      "[408 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(len(df_pmm))\n",
    "print(df_pmm[0]) #looks like indices not preserved. Shouldn't be a problem since data is fully imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "a4536b35-0261-48de-b0cd-6c0f52f2b4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"C:\\\\Users\\\\J\\\\from_R\\\\cart\"\n",
    "csv_cart = [file for file in os.listdir(folder_path) if file.endswith(\".csv\")]\n",
    "df_cart = []\n",
    "for file in csv_cart:\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    df_cart.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "9c55aea6-381b-465e-9ec0-113a3324959b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "     Length  Width  Height\n",
      "0    102.67  49.53   19.69\n",
      "1    102.50  51.42   18.66\n",
      "2     95.37  52.25   21.51\n",
      "3     94.77  49.24   18.60\n",
      "4    104.26  47.90   19.46\n",
      "..      ...    ...     ...\n",
      "403   98.34  49.03   19.30\n",
      "404  101.24  50.00   20.96\n",
      "405   98.37  52.12   19.68\n",
      "406   94.16  48.39   21.60\n",
      "407  102.35  51.24   21.47\n",
      "\n",
      "[408 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(len(df_cart))\n",
    "print(df_cart[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "d4ba4df1-1b2d-43b4-9ab8-b4b0c690eef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"C:\\\\Users\\\\J\\\\from_R\\\\BLR\"\n",
    "csv_BLR = [file for file in os.listdir(folder_path) if file.endswith(\".csv\")]\n",
    "df_BLR = []\n",
    "for file in csv_BLR:\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    df_BLR.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "c6df9ba5-900c-46e2-b65b-0f02413af4de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "     Length      Width     Height\n",
      "0    102.67  49.530000  19.690000\n",
      "1    102.50  48.035976  18.607753\n",
      "2     95.37  52.250000  21.510000\n",
      "3     94.77  49.240000  18.600000\n",
      "4    104.26  47.900000  19.460000\n",
      "..      ...        ...        ...\n",
      "403   98.34  49.030000  19.300000\n",
      "404  101.24  48.735525  20.960000\n",
      "405   98.37  52.120000  19.680000\n",
      "406   94.16  48.390000  21.600000\n",
      "407  102.35  51.240000  21.470000\n",
      "\n",
      "[408 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(len(df_BLR))\n",
    "print(df_BLR[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "9f25e538-91a3-4c9e-91bb-a098ee8a0283",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"C:\\\\Users\\\\J\\\\from_R\\\\RF\"\n",
    "csv_RF = [file for file in os.listdir(folder_path) if file.endswith(\".csv\")]\n",
    "df_RF = []\n",
    "for file in csv_RF:\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    df_RF.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "25e3beb3-822a-42ac-96a1-e2b6e4ec9db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "     Length  Width  Height\n",
      "0    102.67  49.53   19.69\n",
      "1    102.50  50.61   19.63\n",
      "2     95.37  52.25   21.51\n",
      "3     94.77  49.24   18.60\n",
      "4    104.26  47.90   19.46\n",
      "..      ...    ...     ...\n",
      "403   98.34  49.03   19.30\n",
      "404  101.24  52.46   20.96\n",
      "405   98.37  52.12   19.68\n",
      "406   94.16  48.39   21.60\n",
      "407  102.35  51.24   21.47\n",
      "\n",
      "[408 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(len(df_RF))\n",
    "print(df_RF[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "0ff45d2c-3a13-4122-8a7b-af3f78668d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(GT)\n",
    "def extract_imputed_values(original_dfs, imputed_dfs):\n",
    "    imputed_values_list = []\n",
    "    num_original_dfs = len(original_dfs)\n",
    "    num_imputed_dfs = len(imputed_dfs)\n",
    "    num_imputations_per_set = num_imputed_dfs // num_original_dfs\n",
    "    \n",
    "    for i in range(num_original_dfs):\n",
    "        start_index = i * num_imputations_per_set\n",
    "        end_index = start_index + num_imputations_per_set\n",
    "\n",
    "        original_df = original_dfs[i].reset_index(drop=True)  # Reset the index\n",
    "        \n",
    "        for j in range(start_index, end_index):\n",
    "            imputed_df = imputed_dfs[j]\n",
    "            # Create a boolean mask where True indicates the position of NaN values in the original DataFrame\n",
    "            mask = original_df.isna()\n",
    "\n",
    "            # Use the mask to extract the imputed values from the imputed DataFrame\n",
    "            imputed_values = imputed_df[mask]\n",
    "\n",
    "            imputed_values_list.append(imputed_values)\n",
    "\n",
    "    return imputed_values_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "e8c54ed0-447c-4c0b-8420-9de8d605ae65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#going to reupload the exact dataset used in R\n",
    "folder_path = \"C:\\\\Users\\\\J\\\\dataframes_missing\\\\\"\n",
    "csv_gtm = [file for file in os.listdir(folder_path) if file.endswith(\".csv\")]\n",
    "df_gtm = []\n",
    "for file in csv_gtm:\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    df_gtm.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "fdea5a5f-4dd1-43b5-955a-14b7bc9be3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#going to reupload the exact dataset used in R got the missing values\n",
    "folder_path = \"C:\\\\Users\\\\J\\\\dataframes_GT\\\\\"\n",
    "csv_gt = [file for file in os.listdir(folder_path) if file.endswith(\".csv\")]\n",
    "df_gt = []\n",
    "for file in csv_gt:\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    df_gt.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "ea3abecc-91fa-49dd-a293-72a2436a0b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(GT)\n",
    "def extract_imputed_values1(original_gts, imputed_dfs):\n",
    "    imputed_values_list = []\n",
    "    num_original_gts = len(original_gts)\n",
    "    num_imputed_dfs = len(imputed_dfs)\n",
    "    num_imputations_per_set = num_imputed_dfs // num_original_gts\n",
    "    \n",
    "    for i in range(num_original_gts):\n",
    "        start_index = i * num_imputations_per_set\n",
    "        end_index = start_index + num_imputations_per_set\n",
    "\n",
    "        original_df = original_gts[i].reset_index(drop=True)  # Reset the index\n",
    "        \n",
    "        for j in range(start_index, end_index):\n",
    "            imputed_df = imputed_dfs[j]\n",
    "            # Create a boolean mask where True indicates the position of NaN values in the original DataFrame\n",
    "            mask = original_df.isna()\n",
    "\n",
    "            # Use the mask to extract the imputed values from the imputed DataFrame\n",
    "            imputed_values = imputed_df[mask]\n",
    "\n",
    "            imputed_values_list.append(imputed_values)\n",
    "\n",
    "    return imputed_values_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "20eb5d12-5879-4b3b-bd89-72adfdb3db17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "408\n"
     ]
    }
   ],
   "source": [
    "df_pmm_imputes = extract_imputed_values1(df_gt, df_pmm)\n",
    "print(len(df_pmm_imputes))\n",
    "print(len(df_pmm_imputes[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "f2055089-a64a-4e96-9cee-e40ef4c551bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "55\n"
     ]
    }
   ],
   "source": [
    "df_pmm_imputedOnly = NaNfilter(df_pmm_imputes)\n",
    "print(len(df_pmm_imputedOnly))\n",
    "print(len(df_pmm_imputedOnly[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "797db64e-fde2-4701-b0c2-de5f11e401ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n",
      "55\n",
      "55\n",
      "55\n",
      "55\n",
      "55\n",
      "55\n",
      "55\n",
      "55\n",
      "154\n",
      "154\n",
      "154\n",
      "154\n",
      "154\n",
      "154\n",
      "154\n",
      "154\n",
      "154\n",
      "XXX\n",
      "55\n",
      "55\n",
      "55\n",
      "156\n",
      "156\n",
      "156\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(df_pmm_imputedOnly)):\n",
    "    print(len(df_pmm_imputedOnly[i]))\n",
    "print(\"XXX\")\n",
    "for i in range(len(df_gt)):\n",
    "    print(len(df_gt[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "dbd54465-e92a-4502-aacb-76aa18daa6a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "408\n"
     ]
    }
   ],
   "source": [
    "df_blr_imputes = extract_imputed_values1(df_gt, df_BLR)\n",
    "print(len(df_blr_imputes))\n",
    "print(len(df_blr_imputes[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "cd126b0f-b765-49a4-a9bd-3dd5897684cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "55\n",
      "XXX\n",
      "55\n",
      "55\n",
      "55\n",
      "55\n",
      "55\n",
      "55\n",
      "55\n",
      "55\n",
      "55\n",
      "154\n",
      "154\n",
      "154\n",
      "154\n",
      "154\n",
      "154\n",
      "154\n",
      "154\n",
      "154\n"
     ]
    }
   ],
   "source": [
    "df_blr_imputedOnly = NaNfilter(df_blr_imputes)\n",
    "print(len(df_blr_imputedOnly))\n",
    "print(len(df_blr_imputedOnly[0]))\n",
    "print(\"XXX\")\n",
    "for i in range(len(df_blr_imputedOnly)):\n",
    "    print(len(df_blr_imputedOnly[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "8ea3c44f-fbe2-4937-98f6-28c67dfb0932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "408\n",
      "XXX\n",
      "18\n",
      "55\n",
      "XXX\n",
      "55\n",
      "55\n",
      "55\n",
      "55\n",
      "55\n",
      "55\n",
      "55\n",
      "55\n",
      "55\n",
      "154\n",
      "154\n",
      "154\n",
      "154\n",
      "154\n",
      "154\n",
      "154\n",
      "154\n",
      "154\n"
     ]
    }
   ],
   "source": [
    "df_cart_imputes = extract_imputed_values1(df_gt, df_cart)\n",
    "print(len(df_cart_imputes))\n",
    "print(len(df_cart_imputes[0]))\n",
    "print(\"XXX\")\n",
    "df_cart_imputedOnly = NaNfilter(df_cart_imputes)\n",
    "print(len(df_cart_imputedOnly))\n",
    "print(len(df_cart_imputedOnly[0]))\n",
    "print(\"XXX\")\n",
    "for i in range(len(df_cart_imputedOnly)):\n",
    "    print(len(df_cart_imputedOnly[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "07a10d5d-4546-4243-af55-41fa20b4b47f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "408\n",
      "XXX\n",
      "18\n",
      "55\n",
      "XXX\n",
      "55\n",
      "55\n",
      "55\n",
      "55\n",
      "55\n",
      "55\n",
      "55\n",
      "55\n",
      "55\n",
      "154\n",
      "154\n",
      "154\n",
      "154\n",
      "154\n",
      "154\n",
      "154\n",
      "154\n",
      "154\n"
     ]
    }
   ],
   "source": [
    "df_RF_imputes = extract_imputed_values1(df_gt, df_RF)\n",
    "print(len(df_RF_imputes))\n",
    "print(len(df_RF_imputes[0]))\n",
    "print(\"XXX\")\n",
    "df_RF_imputedOnly = NaNfilter(df_RF_imputes)\n",
    "print(len(df_RF_imputedOnly))\n",
    "print(len(df_RF_imputedOnly[0]))\n",
    "print(\"XXX\")\n",
    "for i in range(len(df_RF_imputedOnly)):\n",
    "    print(len(df_RF_imputedOnly[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "23cecc35-5838-45fc-96ab-605a07f7442b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pmm_imputes = df_pmm_imputes[0:6]\n",
    "df_pmm_imputes = df_pmm_imputes[0:6]\n",
    "df_blr_imputes = df_blr_imputes[0:6]\n",
    "df_RF_imputes = df_RF_imputes[0:6]\n",
    "df_gt = df_gt[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "d0530317-df2f-45e8-b7d5-a648a6f701ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy1(groundTruth, predictedData):\n",
    "    num_ground_truth = len(groundTruth)\n",
    "    num_predicted_data = len(predictedData)\n",
    "    num_imputations_per_set = num_predicted_data // num_ground_truth\n",
    "    \n",
    "    accuracy_results_df = []\n",
    "    accuracy_results_col = []\n",
    "    \n",
    "    for i in range(num_ground_truth):\n",
    "        start_index = i * num_imputations_per_set\n",
    "        end_index = start_index + num_imputations_per_set\n",
    "\n",
    "        # flatten ground truth for ground truth df\n",
    "        gt_df = groundTruth[i]\n",
    "        \n",
    "        gt_df_Series = pd.Series()\n",
    "        for col in gt_df.columns:\n",
    "            gt_df_Series = pd.concat([gt_df_Series, gt_df[col].dropna()])\n",
    "        gt_df_Series = gt_df_Series.reset_index(drop=True)\n",
    "\n",
    "        # flatten ground truth for each column \n",
    "        gt_col_Series = []\n",
    "        for col in gt_df.columns:\n",
    "            series = gt_df[col]\n",
    "            series = series.dropna()\n",
    "            series = series.reset_index(drop=True)\n",
    "            gt_col_Series.append(pd.Series(series))\n",
    "        \n",
    "        for j in range(start_index, end_index):\n",
    "            pd_df = predictedData[j] # Get the predicted data for this imputation\n",
    "        \n",
    "            pd_df_Series = pd.Series()\n",
    "            for col in pd_df.columns:\n",
    "                pd_df_Series = pd.concat([pd_df_Series, pd_df[col].dropna()])\n",
    "            pd_df_Series = pd_df_Series.reset_index(drop=True)\n",
    "\n",
    "            # flatten ground truth for each column \n",
    "            pd_col_Series = []\n",
    "            for col in pd_df.columns:\n",
    "                series = pd_df[col]\n",
    "                series = series.dropna()\n",
    "                series = series.reset_index(drop=True)\n",
    "                pd_col_Series.append(pd.Series(series))\n",
    "\n",
    "            # Calculate metrics at the df level\n",
    "            accuracyPercent_df = np.round((gt_df_Series - pd_df_Series) / gt_df_Series * 100)\n",
    "            mean_accuracy_df = np.round(np.mean(accuracyPercent_df), 2)\n",
    "            stdev_accuracy_df = np.round(np.std(accuracyPercent_df), 2)\n",
    "            var_df = np.round(predictedData[j].var(), 2)\n",
    "            #mse_df = np.round(mean_squared_error(gt_df_Series, pd_df_Series, squared=False), 2)\n",
    "            \n",
    "            accuracy_results_df.append((accuracyPercent_df, mean_accuracy_df, \n",
    "                                     stdev_accuracy_df, var_df))#, mse_df\n",
    "\n",
    "            # Calculate metrics at the col level\n",
    "            for A, B in zip(gt_col_Series, pd_col_Series):\n",
    "                    accuracyPercent_col = np.round((A - B) / A * 100)\n",
    "                    mean_accuracy_col = np.round(np.mean(accuracyPercent_col), 2)\n",
    "                    stdev_accuracy_col = np.round(np.std(accuracyPercent_col), 2)\n",
    "                    var_col = np.round(B.var(), 2)\n",
    "                    #mse_col = np.round(mean_squared_error(A, B, squared=False), 2)\n",
    "                    \n",
    "                    accuracy_results_col.append((accuracyPercent_col, mean_accuracy_col,\n",
    "                                            stdev_accuracy_col, var_col))#, mse_col\n",
    "    \n",
    "    print(\"accuracy results cell by cell for df \\n\", \"accuracy % across df:\", mean_accuracy_df, \"\\n\",\n",
    "          \"stdev across df:\", stdev_accuracy_df, \"\\n\", \"variance across df:\", var_df, \"\\n\",\n",
    "           \"accuracy results cell by cell for columns \\n\", \"accuracy % across column:\", #\"mse across df:\", mse_df, \"\\n\",\n",
    "          mean_accuracy_col, \"\\n\", \"stdev across column:\", stdev_accuracy_col, \"\\n\", \"variance across col:\",\n",
    "          var_col, \"\\n\")#, \"mse across column:\", mse_col\n",
    "    \n",
    "    return accuracy_results_df, accuracy_results_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "868ec1cc-81cf-413a-86e5-0bd8a5f6d2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy results cell by cell for df \n",
      " accuracy % across df: -73.65 \n",
      " stdev across df: 65.15 \n",
      " variance across df: Length    12.20\n",
      "Width      3.94\n",
      "Height     0.93\n",
      "dtype: float64 \n",
      " accuracy results cell by cell for columns \n",
      " accuracy % across column: 2.6 \n",
      " stdev across column: 5.36 \n",
      " variance across col: 0.93 \n",
      "\n",
      "accuracy results cell by cell for df \n",
      " accuracy % across df: -167.53 \n",
      " stdev across df: 170.01 \n",
      " variance across df: Length    13.84\n",
      "Width      3.50\n",
      "Height     0.98\n",
      "dtype: float64 \n",
      " accuracy results cell by cell for columns \n",
      " accuracy % across column: 1.15 \n",
      " stdev across column: 5.98 \n",
      " variance across col: 0.98 \n",
      "\n",
      "accuracy results cell by cell for df \n",
      " accuracy % across df: -74.47 \n",
      " stdev across df: 66.02 \n",
      " variance across df: Length    12.32\n",
      "Width      3.93\n",
      "Height     0.89\n",
      "dtype: float64 \n",
      " accuracy results cell by cell for columns \n",
      " accuracy % across column: 1.7 \n",
      " stdev across column: 5.23 \n",
      " variance across col: 0.89 \n",
      "\n",
      "accuracy results cell by cell for df \n",
      " accuracy % across df: -73.83 \n",
      " stdev across df: 65.47 \n",
      " variance across df: Length    12.38\n",
      "Width      3.96\n",
      "Height     0.95\n",
      "dtype: float64 \n",
      " accuracy results cell by cell for columns \n",
      " accuracy % across column: 1.7 \n",
      " stdev across column: 6.06 \n",
      " variance across col: 0.95 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\J\\AppData\\Local\\Temp\\ipykernel_33892\\1213763440.py:18: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  gt_df_Series = pd.concat([gt_df_Series, gt_df[col].dropna()])\n",
      "C:\\Users\\J\\AppData\\Local\\Temp\\ipykernel_33892\\1213763440.py:34: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  pd_df_Series = pd.concat([pd_df_Series, pd_df[col].dropna()])\n",
      "C:\\Users\\J\\AppData\\Local\\Temp\\ipykernel_33892\\1213763440.py:34: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  pd_df_Series = pd.concat([pd_df_Series, pd_df[col].dropna()])\n",
      "C:\\Users\\J\\AppData\\Local\\Temp\\ipykernel_33892\\1213763440.py:18: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  gt_df_Series = pd.concat([gt_df_Series, gt_df[col].dropna()])\n",
      "C:\\Users\\J\\AppData\\Local\\Temp\\ipykernel_33892\\1213763440.py:34: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  pd_df_Series = pd.concat([pd_df_Series, pd_df[col].dropna()])\n",
      "C:\\Users\\J\\AppData\\Local\\Temp\\ipykernel_33892\\1213763440.py:34: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  pd_df_Series = pd.concat([pd_df_Series, pd_df[col].dropna()])\n",
      "C:\\Users\\J\\AppData\\Local\\Temp\\ipykernel_33892\\1213763440.py:18: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  gt_df_Series = pd.concat([gt_df_Series, gt_df[col].dropna()])\n",
      "C:\\Users\\J\\AppData\\Local\\Temp\\ipykernel_33892\\1213763440.py:34: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  pd_df_Series = pd.concat([pd_df_Series, pd_df[col].dropna()])\n",
      "C:\\Users\\J\\AppData\\Local\\Temp\\ipykernel_33892\\1213763440.py:34: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  pd_df_Series = pd.concat([pd_df_Series, pd_df[col].dropna()])\n",
      "C:\\Users\\J\\AppData\\Local\\Temp\\ipykernel_33892\\1213763440.py:18: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  gt_df_Series = pd.concat([gt_df_Series, gt_df[col].dropna()])\n",
      "C:\\Users\\J\\AppData\\Local\\Temp\\ipykernel_33892\\1213763440.py:34: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  pd_df_Series = pd.concat([pd_df_Series, pd_df[col].dropna()])\n",
      "C:\\Users\\J\\AppData\\Local\\Temp\\ipykernel_33892\\1213763440.py:34: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  pd_df_Series = pd.concat([pd_df_Series, pd_df[col].dropna()])\n",
      "C:\\Users\\J\\AppData\\Local\\Temp\\ipykernel_33892\\1213763440.py:34: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  pd_df_Series = pd.concat([pd_df_Series, pd_df[col].dropna()])\n",
      "C:\\Users\\J\\AppData\\Local\\Temp\\ipykernel_33892\\1213763440.py:34: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  pd_df_Series = pd.concat([pd_df_Series, pd_df[col].dropna()])\n",
      "C:\\Users\\J\\AppData\\Local\\Temp\\ipykernel_33892\\1213763440.py:34: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  pd_df_Series = pd.concat([pd_df_Series, pd_df[col].dropna()])\n",
      "C:\\Users\\J\\AppData\\Local\\Temp\\ipykernel_33892\\1213763440.py:34: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  pd_df_Series = pd.concat([pd_df_Series, pd_df[col].dropna()])\n",
      "C:\\Users\\J\\AppData\\Local\\Temp\\ipykernel_33892\\1213763440.py:18: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  gt_df_Series = pd.concat([gt_df_Series, gt_df[col].dropna()])\n",
      "C:\\Users\\J\\AppData\\Local\\Temp\\ipykernel_33892\\1213763440.py:34: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  pd_df_Series = pd.concat([pd_df_Series, pd_df[col].dropna()])\n",
      "C:\\Users\\J\\AppData\\Local\\Temp\\ipykernel_33892\\1213763440.py:34: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  pd_df_Series = pd.concat([pd_df_Series, pd_df[col].dropna()])\n",
      "C:\\Users\\J\\AppData\\Local\\Temp\\ipykernel_33892\\1213763440.py:34: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  pd_df_Series = pd.concat([pd_df_Series, pd_df[col].dropna()])\n",
      "C:\\Users\\J\\AppData\\Local\\Temp\\ipykernel_33892\\1213763440.py:34: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  pd_df_Series = pd.concat([pd_df_Series, pd_df[col].dropna()])\n",
      "C:\\Users\\J\\AppData\\Local\\Temp\\ipykernel_33892\\1213763440.py:34: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  pd_df_Series = pd.concat([pd_df_Series, pd_df[col].dropna()])\n",
      "C:\\Users\\J\\AppData\\Local\\Temp\\ipykernel_33892\\1213763440.py:34: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  pd_df_Series = pd.concat([pd_df_Series, pd_df[col].dropna()])\n",
      "C:\\Users\\J\\AppData\\Local\\Temp\\ipykernel_33892\\1213763440.py:18: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  gt_df_Series = pd.concat([gt_df_Series, gt_df[col].dropna()])\n",
      "C:\\Users\\J\\AppData\\Local\\Temp\\ipykernel_33892\\1213763440.py:34: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  pd_df_Series = pd.concat([pd_df_Series, pd_df[col].dropna()])\n",
      "C:\\Users\\J\\AppData\\Local\\Temp\\ipykernel_33892\\1213763440.py:34: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  pd_df_Series = pd.concat([pd_df_Series, pd_df[col].dropna()])\n",
      "C:\\Users\\J\\AppData\\Local\\Temp\\ipykernel_33892\\1213763440.py:34: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  pd_df_Series = pd.concat([pd_df_Series, pd_df[col].dropna()])\n",
      "C:\\Users\\J\\AppData\\Local\\Temp\\ipykernel_33892\\1213763440.py:34: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  pd_df_Series = pd.concat([pd_df_Series, pd_df[col].dropna()])\n",
      "C:\\Users\\J\\AppData\\Local\\Temp\\ipykernel_33892\\1213763440.py:34: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  pd_df_Series = pd.concat([pd_df_Series, pd_df[col].dropna()])\n",
      "C:\\Users\\J\\AppData\\Local\\Temp\\ipykernel_33892\\1213763440.py:34: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  pd_df_Series = pd.concat([pd_df_Series, pd_df[col].dropna()])\n",
      "C:\\Users\\J\\AppData\\Local\\Temp\\ipykernel_33892\\1213763440.py:18: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  gt_df_Series = pd.concat([gt_df_Series, gt_df[col].dropna()])\n",
      "C:\\Users\\J\\AppData\\Local\\Temp\\ipykernel_33892\\1213763440.py:34: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  pd_df_Series = pd.concat([pd_df_Series, pd_df[col].dropna()])\n",
      "C:\\Users\\J\\AppData\\Local\\Temp\\ipykernel_33892\\1213763440.py:34: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  pd_df_Series = pd.concat([pd_df_Series, pd_df[col].dropna()])\n",
      "C:\\Users\\J\\AppData\\Local\\Temp\\ipykernel_33892\\1213763440.py:18: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  gt_df_Series = pd.concat([gt_df_Series, gt_df[col].dropna()])\n",
      "C:\\Users\\J\\AppData\\Local\\Temp\\ipykernel_33892\\1213763440.py:34: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  pd_df_Series = pd.concat([pd_df_Series, pd_df[col].dropna()])\n",
      "C:\\Users\\J\\AppData\\Local\\Temp\\ipykernel_33892\\1213763440.py:34: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  pd_df_Series = pd.concat([pd_df_Series, pd_df[col].dropna()])\n",
      "C:\\Users\\J\\AppData\\Local\\Temp\\ipykernel_33892\\1213763440.py:18: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  gt_df_Series = pd.concat([gt_df_Series, gt_df[col].dropna()])\n",
      "C:\\Users\\J\\AppData\\Local\\Temp\\ipykernel_33892\\1213763440.py:34: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  pd_df_Series = pd.concat([pd_df_Series, pd_df[col].dropna()])\n",
      "C:\\Users\\J\\AppData\\Local\\Temp\\ipykernel_33892\\1213763440.py:34: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  pd_df_Series = pd.concat([pd_df_Series, pd_df[col].dropna()])\n",
      "C:\\Users\\J\\AppData\\Local\\Temp\\ipykernel_33892\\1213763440.py:18: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  gt_df_Series = pd.concat([gt_df_Series, gt_df[col].dropna()])\n",
      "C:\\Users\\J\\AppData\\Local\\Temp\\ipykernel_33892\\1213763440.py:34: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  pd_df_Series = pd.concat([pd_df_Series, pd_df[col].dropna()])\n",
      "C:\\Users\\J\\AppData\\Local\\Temp\\ipykernel_33892\\1213763440.py:34: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  pd_df_Series = pd.concat([pd_df_Series, pd_df[col].dropna()])\n",
      "C:\\Users\\J\\AppData\\Local\\Temp\\ipykernel_33892\\1213763440.py:18: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  gt_df_Series = pd.concat([gt_df_Series, gt_df[col].dropna()])\n",
      "C:\\Users\\J\\AppData\\Local\\Temp\\ipykernel_33892\\1213763440.py:34: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  pd_df_Series = pd.concat([pd_df_Series, pd_df[col].dropna()])\n",
      "C:\\Users\\J\\AppData\\Local\\Temp\\ipykernel_33892\\1213763440.py:34: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  pd_df_Series = pd.concat([pd_df_Series, pd_df[col].dropna()])\n",
      "C:\\Users\\J\\AppData\\Local\\Temp\\ipykernel_33892\\1213763440.py:18: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  gt_df_Series = pd.concat([gt_df_Series, gt_df[col].dropna()])\n",
      "C:\\Users\\J\\AppData\\Local\\Temp\\ipykernel_33892\\1213763440.py:34: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  pd_df_Series = pd.concat([pd_df_Series, pd_df[col].dropna()])\n",
      "C:\\Users\\J\\AppData\\Local\\Temp\\ipykernel_33892\\1213763440.py:34: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  pd_df_Series = pd.concat([pd_df_Series, pd_df[col].dropna()])\n"
     ]
    }
   ],
   "source": [
    "acc_pmm = accuracy1(df_gt, df_pmm_imputes)\n",
    "acc_cart = accuracy1(df_gt, df_cart_imputes)\n",
    "acc_blr = accuracy1(df_gt, df_blr_imputes)\n",
    "acc_RF = accuracy1(df_gt, df_RF_imputes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "09b23650-543d-4863-8c11-7dedbb5d6d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = max_df_accuracy_list(acc_pmm[1])\n",
    "c = max_df_accuracy_list(acc_cart[1])\n",
    "b = max_df_accuracy_list(acc_blr[1])\n",
    "r = max_df_accuracy_list(acc_RF[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "94d1954f-9732-4f37-85bc-1ab0585fb711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4, 0.2),\n",
       " (15, 0.4),\n",
       " (10, 0.5),\n",
       " (0, 0.6),\n",
       " (3, 0.6),\n",
       " (9, 0.6),\n",
       " (12, 0.6),\n",
       " (6, 0.65),\n",
       " (11, 0.7),\n",
       " (1, 0.75),\n",
       " (13, 0.85),\n",
       " (7, 0.9),\n",
       " (16, 1.1),\n",
       " (5, 1.35),\n",
       " (14, 1.35),\n",
       " (2, 1.4),\n",
       " (8, 2.35),\n",
       " (17, 2.6)]"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "d27f2cfa-fdd9-40ae-99ab-bab3fca6832b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "print(len(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "04f9756c-30d8-4a1b-afb3-8b33d837abdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(28, 0.05),\n",
       " (22, 0.1),\n",
       " (24, 0.15),\n",
       " (3, 0.2),\n",
       " (15, 0.2),\n",
       " (10, 0.3),\n",
       " (1, 0.4),\n",
       " (9, 0.4),\n",
       " (16, 0.4),\n",
       " (21, 0.4),\n",
       " (18, 0.45),\n",
       " (6, 0.5),\n",
       " (0, 0.55),\n",
       " (12, 0.55),\n",
       " (13, 0.6),\n",
       " (25, 0.6),\n",
       " (49, 0.6),\n",
       " (52, 0.65),\n",
       " (4, 0.75),\n",
       " (34, 0.75),\n",
       " (31, 0.8),\n",
       " (35, 0.85),\n",
       " (40, 0.85),\n",
       " (7, 0.9),\n",
       " (43, 0.9),\n",
       " (46, 0.9),\n",
       " (19, 0.95),\n",
       " (50, 0.95),\n",
       " (44, 1.0),\n",
       " (37, 1.15),\n",
       " (47, 1.15),\n",
       " (53, 1.15),\n",
       " (11, 1.25),\n",
       " (23, 1.25),\n",
       " (41, 1.25),\n",
       " (27, 1.3),\n",
       " (20, 1.35),\n",
       " (33, 1.35),\n",
       " (45, 1.35),\n",
       " (51, 1.35),\n",
       " (2, 1.4),\n",
       " (30, 1.4),\n",
       " (36, 1.5),\n",
       " (39, 1.5),\n",
       " (42, 1.5),\n",
       " (29, 1.55),\n",
       " (38, 1.55),\n",
       " (48, 1.65),\n",
       " (14, 1.75),\n",
       " (32, 1.8),\n",
       " (26, 2.05),\n",
       " (5, 2.2),\n",
       " (17, 2.45),\n",
       " (8, 2.65)]"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "fa21e0b8-7c8d-4956-8a35-a8f14ba11511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 0.15),\n",
       " (10, 0.15),\n",
       " (13, 0.2),\n",
       " (16, 0.3),\n",
       " (15, 0.35),\n",
       " (6, 0.5),\n",
       " (9, 0.5),\n",
       " (4, 0.55),\n",
       " (0, 0.6),\n",
       " (1, 0.6),\n",
       " (5, 0.65),\n",
       " (12, 0.65),\n",
       " (7, 0.8),\n",
       " (14, 1.2),\n",
       " (2, 1.4),\n",
       " (8, 1.55),\n",
       " (17, 1.7),\n",
       " (11, 2.0)]"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "afff92da-da55-4ef1-9e88-d0d86860aed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(12, 0.05),\n",
       " (13, 0.25),\n",
       " (6, 0.3),\n",
       " (3, 0.4),\n",
       " (9, 0.4),\n",
       " (15, 0.45),\n",
       " (0, 0.5),\n",
       " (1, 0.6),\n",
       " (7, 0.9),\n",
       " (10, 0.9),\n",
       " (4, 0.95),\n",
       " (14, 1.05),\n",
       " (16, 1.05),\n",
       " (2, 1.4),\n",
       " (11, 1.45),\n",
       " (5, 1.5),\n",
       " (17, 1.7),\n",
       " (8, 2.15)]"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b053211-901f-4996-aad7-525d7ed844f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f141a61-ef12-49c4-913f-77780f2fdbda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad61deda-f832-4800-bcad-6bcc2215ea70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "c7b652a8-69bb-427d-8007-e0ec9b35b602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n",
      "408\n",
      "18\n",
      "408\n"
     ]
    }
   ],
   "source": [
    "print(len(GT_for_test[0]))\n",
    "print(len(pmm[0]))\n",
    "\n",
    "print(len(pmm_imputed_wNaN))\n",
    "print(len(pmm_imputed_wNaN[0]))\n",
    "#print(pmm_imputed_wNaN[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368f0f5f-5abb-4cd4-9057-62813a96e160",
   "metadata": {},
   "outputs": [],
   "source": [
    "blr_imputed_wNaN = extract_imputed_values(GT_for_test, df_BLR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "42ec6fad-f5d2-453c-a68d-66305d6bfa49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\J\\AppData\\Local\\Temp\\ipykernel_33892\\4028562387.py:18: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  gt_df_Series = pd.concat([gt_df_Series, gt_df[col].dropna()])\n",
      "C:\\Users\\J\\AppData\\Local\\Temp\\ipykernel_33892\\4028562387.py:34: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  pd_df_Series = pd.concat([pd_df_Series, pd_df[col].dropna()])\n",
      "C:\\Users\\J\\AppData\\Local\\Temp\\ipykernel_33892\\4028562387.py:34: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  pd_df_Series = pd.concat([pd_df_Series, pd_df[col].dropna()])\n",
      "C:\\Users\\J\\AppData\\Local\\Temp\\ipykernel_33892\\4028562387.py:34: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  pd_df_Series = pd.concat([pd_df_Series, pd_df[col].dropna()])\n",
      "C:\\Users\\J\\AppData\\Local\\Temp\\ipykernel_33892\\4028562387.py:18: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  gt_df_Series = pd.concat([gt_df_Series, gt_df[col].dropna()])\n",
      "C:\\Users\\J\\AppData\\Local\\Temp\\ipykernel_33892\\4028562387.py:34: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  pd_df_Series = pd.concat([pd_df_Series, pd_df[col].dropna()])\n",
      "C:\\Users\\J\\AppData\\Local\\Temp\\ipykernel_33892\\4028562387.py:34: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  pd_df_Series = pd.concat([pd_df_Series, pd_df[col].dropna()])\n",
      "C:\\Users\\J\\AppData\\Local\\Temp\\ipykernel_33892\\4028562387.py:34: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  pd_df_Series = pd.concat([pd_df_Series, pd_df[col].dropna()])\n",
      "C:\\Users\\J\\AppData\\Local\\Temp\\ipykernel_33892\\4028562387.py:18: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  gt_df_Series = pd.concat([gt_df_Series, gt_df[col].dropna()])\n",
      "C:\\Users\\J\\AppData\\Local\\Temp\\ipykernel_33892\\4028562387.py:34: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  pd_df_Series = pd.concat([pd_df_Series, pd_df[col].dropna()])\n",
      "C:\\Users\\J\\AppData\\Local\\Temp\\ipykernel_33892\\4028562387.py:34: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  pd_df_Series = pd.concat([pd_df_Series, pd_df[col].dropna()])\n",
      "C:\\Users\\J\\AppData\\Local\\Temp\\ipykernel_33892\\4028562387.py:34: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  pd_df_Series = pd.concat([pd_df_Series, pd_df[col].dropna()])\n",
      "C:\\Users\\J\\AppData\\Local\\Temp\\ipykernel_33892\\4028562387.py:18: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  gt_df_Series = pd.concat([gt_df_Series, gt_df[col].dropna()])\n",
      "C:\\Users\\J\\AppData\\Local\\Temp\\ipykernel_33892\\4028562387.py:34: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  pd_df_Series = pd.concat([pd_df_Series, pd_df[col].dropna()])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [66, 62]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[320], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m pmm_acc \u001b[38;5;241m=\u001b[39m \u001b[43maccuracy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mGT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimputed_pmm\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[72], line 50\u001b[0m, in \u001b[0;36maccuracy\u001b[1;34m(groundTruth, predictedData)\u001b[0m\n\u001b[0;32m     48\u001b[0m stdev_accuracy_df \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mround(np\u001b[38;5;241m.\u001b[39mstd(accuracyPercent_df), \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     49\u001b[0m var_df \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mround(predictedData[j]\u001b[38;5;241m.\u001b[39mvar(), \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m---> 50\u001b[0m mse_df \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mround(\u001b[43mmean_squared_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgt_df_Series\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpd_df_Series\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msquared\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     52\u001b[0m accuracy_results_df\u001b[38;5;241m.\u001b[39mappend((accuracyPercent_df, mean_accuracy_df, \n\u001b[0;32m     53\u001b[0m                          stdev_accuracy_df, var_df, mse_df))\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# Calculate metrics at the col level\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\r_environment_in_jupyternotbook\\lib\\site-packages\\sklearn\\metrics\\_regression.py:442\u001b[0m, in \u001b[0;36mmean_squared_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[0;32m    382\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean_squared_error\u001b[39m(\n\u001b[0;32m    383\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, multioutput\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muniform_average\u001b[39m\u001b[38;5;124m\"\u001b[39m, squared\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    384\u001b[0m ):\n\u001b[0;32m    385\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Mean squared error regression loss.\u001b[39;00m\n\u001b[0;32m    386\u001b[0m \n\u001b[0;32m    387\u001b[0m \u001b[38;5;124;03m    Read more in the :ref:`User Guide <mean_squared_error>`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    440\u001b[0m \u001b[38;5;124;03m    0.825...\u001b[39;00m\n\u001b[0;32m    441\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 442\u001b[0m     y_type, y_true, y_pred, multioutput \u001b[38;5;241m=\u001b[39m \u001b[43m_check_reg_targets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    443\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\n\u001b[0;32m    444\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    445\u001b[0m     check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    446\u001b[0m     output_errors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39maverage((y_true \u001b[38;5;241m-\u001b[39m y_pred) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, weights\u001b[38;5;241m=\u001b[39msample_weight)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\r_environment_in_jupyternotbook\\lib\\site-packages\\sklearn\\metrics\\_regression.py:100\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_reg_targets\u001b[39m(y_true, y_pred, multioutput, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     67\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same regression task.\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \n\u001b[0;32m     69\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;124;03m        correct keyword.\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 100\u001b[0m     \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    101\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m check_array(y_true, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    102\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m check_array(y_pred, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\r_environment_in_jupyternotbook\\lib\\site-packages\\sklearn\\utils\\validation.py:387\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    385\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 387\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    388\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    389\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    390\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [66, 62]"
     ]
    }
   ],
   "source": [
    "pmm_acc = accuracy(GT, imputed_pmm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f1d7b4-fda9-4fdb-ad01-8640bd328329",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd86d43-0b1a-47aa-9b52-028fc5d56ea5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fcfca4-6d8f-4a4f-84ca-92af7579f591",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f75c9b-d832-413a-93b3-57612c4cab58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f951e9e-8b18-4b60-a8c1-d0ef5ac24907",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9e1b93-f0f7-469e-841e-d0076d324384",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9ea979-3264-4c91-835f-048d86b6a850",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7d62e1-9a4b-481e-9f3e-a1a50368c4a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40088062-bbf4-4ad7-8712-7037bea292be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e754f4d4-bdf6-48d8-83de-75582492465f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d060b8e-bb6a-46cf-826a-b119b4c037a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b4ca44-87fb-448b-998d-778d994f140b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5e72e4-6f41-4ba8-83df-6b8d078dfbcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "29e88933-d36c-4479-89bf-74d4a22e4195",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "6e0ad16e-330c-4dcb-8a55-ad4f340414b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "3\n",
      "4\n",
      "<class 'tuple'>\n",
      "<class 'tuple'>\n",
      "<class 'numpy.float64'>\n",
      "(0.7, 2.63, 0.0, 2.96)\n",
      "(-0.75, 4.15, 0.0, 2.07)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(len(mice_accuracy_descript_stats))\n",
    "print(len(mice_accuracy_descript_stats[0]))\n",
    "print(len(mice_accuracy_descript_stats[0][0]))\n",
    "print(type(mice_accuracy_descript_stats[0]))\n",
    "print(type(mice_accuracy_descript_stats[0][0]))\n",
    "print(type(mice_accuracy_descript_stats[0][0][0]))\n",
    "print(mice_accuracy_descript_stats[0][0])\n",
    "print(mice_accuracy_descript_stats[0][1])\n",
    "\n",
    "cc = np.array(mice_accuracy_descript_stats[0])\n",
    "\n",
    "for tup in cc:\n",
    "    # Convert tuple to 2D array\n",
    "    data_array = np.array(tup).reshape(1, -1)\n",
    "\n",
    "    # Create heatmap\n",
    "    sns.heatmap(data_array, annot=True, cmap='viridis')\n",
    "\n",
    "\n",
    "#print(cc.shape)\n",
    "#sns.heatmap(cc, annot=True, cmap='viridis')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f3367e-19f5-4b3f-9a6e-81f80bd1cb72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19be4dc3-d4f2-4af3-8367-bb136616c46d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9ef417-8223-4f4c-a8ee-96c2f484afc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e130214-ce4d-49c0-8700-edf26e8b1f79",
   "metadata": {},
   "source": [
    "At this point in the code, I moved over to Google Colab. I wanted to do the whole thing here, but I was having a difficult time with R and some of these libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3398d3a0-9d40-4393-9859-3d05de615046",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "I run R and python through anaconda. This is run locally in my r_jupyternotebook environment. \n",
    "The following libraries were downloaded via anaconda:\n",
    "conda install conda-forge::r-data.table\n",
    "conda install conda-forge::r-ggplot2\n",
    "conda install conda-forge::r-mice\n",
    "conda install conda-forge::r-missforest\n",
    "conda install conda-forge::r-corrplot\n",
    "conda install conda-forge::r-brms\n",
    "conda install conda-forge::r-withr\n",
    "conda install conda-forge::r-rstan\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5073391-b7ae-4302-b83b-e29cef84c145",
   "metadata": {},
   "outputs": [],
   "source": [
    "install.packages(\"rstan\", repos = c(\"https://mc-stan.org/r-packages/\", getOption(\"repos\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc58098-9444-4fc8-b179-58d80e75ad51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "library(data.table)\n",
    "library(mice)\n",
    "library(missForest)\n",
    "library(corrplot)\n",
    "library(ggplot2)\n",
    "library(brms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f57caa-15a5-4060-83f3-e39e2f827d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#library(parallel) #???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7366a318-cdbe-4da6-84b9-709f2df82ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store the data frames\n",
    "df_list <- list()\n",
    "\n",
    "# List all CSV files in the directory\n",
    "csv_files <- list.files(path = \"C:\\\\Users\\\\J\\\\dataframes\", pattern = \"\\\\.csv$\", full.names = TRUE)\n",
    "\n",
    "# Loop through each CSV file\n",
    "for (file in csv_files) {\n",
    "  # Read the CSV file into a data.table\n",
    "  df <- fread(file)\n",
    "  \n",
    "  # Add the data.table to the list\n",
    "  df_list[[file]] <- df\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059005e0-7b28-4929-9c1b-0d162f551748",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(length(df_list))\n",
    "#print(df_list[[4]])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39222db1-90be-4f5f-bc9d-8e336e470891",
   "metadata": {},
   "outputs": [],
   "source": [
    "#confirmed works. retunrs full dataframes\n",
    "miceAuto_pmm <- function(df_list, num_interations) {\n",
    "    complete_mice_imputed_data_final <- list()\n",
    "\n",
    "    # Iterate through dfs in df_list\n",
    "    for (i in 1:length(df_list)) {        \n",
    "        # Iterate through each num_interations\n",
    "        for (j in num_iterations) {\n",
    "            # Process each data table and save the output to the new list\n",
    "            mice_imputed_data <- mice(df_list[[i]], method = \"pmm\", m = j)\n",
    "            complete_mice_imputed_data <- complete(mice_imputed_data,j)\n",
    "            complete_mice_imputed_data_final[[paste0(\"df\", i, \"_imp\", j)]] <- as.data.frame(complete_mice_imputed_data)\n",
    "            print(complete_mice_imputed_data_final)\n",
    "            }\n",
    "        }\n",
    "    return (complete_mice_imputed_data_final)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc4706a-d9c5-44a1-9944-9c2196cfc438",
   "metadata": {},
   "outputs": [],
   "source": [
    "#works as intended\n",
    "clean_onlyImputed <- function(df_list_fully_imputed, df_list_missing) {\n",
    "    num_list_missing <- length(df_list_missing)\n",
    "    num_predicted_data <- length(df_list_fully_imputed)\n",
    "    num_imputations_per_set <- num_predicted_data / num_list_missing\n",
    "    \n",
    "    clean_onlyImputed <- list()\n",
    "    clean_only <- list()\n",
    "\n",
    "    # Iterate through dfs in df_list\n",
    "    for (i in 1:num_list_missing) {\n",
    "        start_index <- (i-1) * num_imputations_per_set + 1\n",
    "        end_index <- start_index + num_imputations_per_set - 1\n",
    "        \n",
    "        missing <- df_list_missing[[i]]\n",
    "\n",
    "        # Iterate through each num_interations\n",
    "        for (j in start_index:end_index) {\n",
    "            full <- df_list_fully_imputed[[j]]\n",
    "            only_mice_imputed_data <- full\n",
    "            only_mice_imputed_data[!is.na(missing)] <- NA\n",
    "            only_mice_imputed_data[[1]] <- full[[1]]\n",
    "            clean_onlyImputed[[paste0(\"df\", i, \"_imp\", j)]] <- only_mice_imputed_data\n",
    "        }\n",
    "        }\n",
    "    #clean_onlyImputed_final <- as.data.frame(clean_onlyImputed)\n",
    "    return (clean_onlyImputed)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310484cc-1dba-474b-802c-246fd681fb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#confirmed works. retunrs full dataframes\n",
    "miceAuto_cart <- function(df_list, num_interations) {\n",
    "    complete_mice_imputed_data_final <- list()\n",
    "\n",
    "    # Iterate through dfs in df_list\n",
    "    for (i in 1:length(df_list)) {        \n",
    "        # Iterate through each num_interations\n",
    "        for (j in num_iterations) {\n",
    "            # Process each data table and save the output to the new list\n",
    "            mice_imputed_data <- mice(df_list[[i]], method = \"cart\", m = j)\n",
    "            complete_mice_imputed_data <- complete(mice_imputed_data,j)\n",
    "            complete_mice_imputed_data_final[[paste0(\"df\", i, \"_imp\", j)]] <- as.data.frame(complete_mice_imputed_data)\n",
    "            print(complete_mice_imputed_data_final)\n",
    "            }\n",
    "        }\n",
    "    return (complete_mice_imputed_data_final)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f745b539-4374-4eb8-9d29-5e8689b2e102",
   "metadata": {},
   "outputs": [],
   "source": [
    "#confirmed works. retunrs full dataframes\n",
    "miceAuto_BLR <- function(df_list, num_interations) {\n",
    "    complete_mice_imputed_data_final <- list()\n",
    "\n",
    "    # Iterate through dfs in df_list\n",
    "    for (i in 1:length(df_list)) {        \n",
    "        # Iterate through each num_interations\n",
    "        for (j in num_iterations) {\n",
    "            # Process each data table and save the output to the new list\n",
    "            mice_imputed_data <- mice(df_list[[i]], method = \"norm\", m = j)\n",
    "            complete_mice_imputed_data <- complete(mice_imputed_data,j)\n",
    "            complete_mice_imputed_data_final[[paste0(\"df\", i, \"_imp\", j)]] <- as.data.frame(complete_mice_imputed_data)\n",
    "            print(complete_mice_imputed_data_final)\n",
    "            }\n",
    "        }\n",
    "    return (complete_mice_imputed_data_final)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f529fc3c-286a-4f51-ab9b-de9547835f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#confirmed works. retunrs full dataframes\n",
    "miceAuto_RF <- function(df_list, num_interations) {\n",
    "    complete_mice_imputed_data_final <- list()\n",
    "\n",
    "    # Iterate through dfs in df_list\n",
    "    for (i in 1:length(df_list)) {        \n",
    "        # Iterate through each num_interations\n",
    "        for (j in num_iterations) {\n",
    "            # Process each data table and save the output to the new list\n",
    "            mice_imputed_data <- mice(df_list[[i]], method = \"rf\", m = j)\n",
    "            complete_mice_imputed_data <- complete(mice_imputed_data,j)\n",
    "            complete_mice_imputed_data_final[[paste0(\"df\", i, \"_imp\", j)]] <- as.data.frame(complete_mice_imputed_data)\n",
    "            print(complete_mice_imputed_data_final)\n",
    "            }\n",
    "        }\n",
    "    return (complete_mice_imputed_data_final)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e7504b-eb39-4fbb-81b3-2b8b1e18280f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#confirmed works. retunrs full dataframes\n",
    "miceAuto_log <- function(df_list, num_interations) {\n",
    "    complete_mice_imputed_data_final <- list()\n",
    "\n",
    "    # Iterate through dfs in df_list\n",
    "    for (i in 1:length(df_list)) {        \n",
    "        # Iterate through each num_interations\n",
    "        for (j in num_iterations) {\n",
    "            # Process each data table and save the output to the new list\n",
    "            mice_imputed_data <- mice(df_list[[i]], method = \"logreg\", m = j)\n",
    "            complete_mice_imputed_data <- complete(mice_imputed_data,j)\n",
    "            complete_mice_imputed_data_final[[paste0(\"df\", i, \"_imp\", j)]] <- as.data.frame(complete_mice_imputed_data)\n",
    "            print(complete_mice_imputed_data_final)\n",
    "            }\n",
    "        }\n",
    "    return (complete_mice_imputed_data_final)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78502b24-8c23-4f1d-8c5f-7d2d5fbe9fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#confirmed works. retunrs full dataframes\n",
    "miceAuto_logregboot <- function(df_list, num_interations) {\n",
    "    complete_mice_imputed_data_final <- list()\n",
    "\n",
    "    # Iterate through dfs in df_list\n",
    "    for (i in 1:length(df_list)) {        \n",
    "        # Iterate through each num_interations\n",
    "        for (j in num_iterations) {\n",
    "            # Process each data table and save the output to the new list\n",
    "            mice_imputed_data <- mice(df_list[[i]], method = \"logreg.boot\", m = j)\n",
    "            complete_mice_imputed_data <- complete(mice_imputed_data,j)\n",
    "            complete_mice_imputed_data_final[[paste0(\"df\", i, \"_imp\", j)]] <- as.data.frame(complete_mice_imputed_data)\n",
    "            print(complete_mice_imputed_data_final)\n",
    "            }\n",
    "        }\n",
    "    return (complete_mice_imputed_data_final)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11684fc3-bdf0-4e59-abf6-88ae5c542229",
   "metadata": {},
   "outputs": [],
   "source": [
    "#confirmed works. retunrs full dataframes\n",
    "missForest_Impute <- function(df_list, num_interations) {\n",
    "    complete_missForest_imputed_data_final <- list()\n",
    "\n",
    "    # Iterate through dfs in df_list\n",
    "    for (i in 1:length(df_list)) {        \n",
    "        # Iterate through each num_interations\n",
    "        for (j in num_iterations) {\n",
    "            # Process each data table and save the output to the new list\n",
    "            missForest_imputed_data <- missForest(df_list[[i]], maxiter = j)\n",
    "            #complete_missForest_imputed_data <- complete(missForest_imputed_data,j)\n",
    "            complete_missForest_imputed_data_final[[paste0(\"df\", i, \"_imp\", j)]] <- as.data.frame(missForest_imputed_data$ximp)\n",
    "            print(complete_missForest_imputed_data_final)\n",
    "            }\n",
    "        }\n",
    "    return (complete_missForest_imputed_data_final)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0039ddd-db0d-4c7a-880a-2ea05f2cf7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 <- list()\n",
    "test2 <- list()\n",
    "test3 <- list()\n",
    "test4 <- list()\n",
    "test5 <- list()\n",
    "test6 <- list()\n",
    "test7 <- list()\n",
    "test1 <- df_list\n",
    "test2 <- df_list\n",
    "test3 <- df_list\n",
    "test4 <- df_list\n",
    "test5 <- df_list\n",
    "test6 <- df_list\n",
    "test7 <- df_list\n",
    "num_iterations <- list(1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33178dbb-dde3-4167-b3cb-03f337bb637a",
   "metadata": {},
   "outputs": [],
   "source": [
    "q <- miceAuto_pmm(test1, num_iterations)\n",
    "print(typeof(q))\n",
    "print(length(q))\n",
    "print(\"XXXXXXXX\")\n",
    "print(typeof(q[[1]]))\n",
    "print(length(q[[1]]))\n",
    "print(q)\n",
    "print(q[[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663b9a96-95a6-465f-8adf-1b935a5778c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#qq <- miceAuto_cart(test2, num_iterations)\n",
    "print(typeof(qq))\n",
    "print(length(qq))\n",
    "print(\"XXXXXXXX\")\n",
    "print(typeof(qq[[1]]))\n",
    "print(length(qq[[1]]))\n",
    "print(qq)\n",
    "print(qq[[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff728b5a-3749-44e8-a603-ba306019ae17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#qqq <- miceAuto_BLR(test3, num_iterations)\n",
    "print(typeof(qqq))\n",
    "print(length(qqq))\n",
    "print(\"XXXXXXXX\")\n",
    "print(typeof(qqq[[1]]))\n",
    "print(length(qqq[[1]]))\n",
    "print(qqq)\n",
    "print(qqq[[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38926c0-5fc5-468c-ba67-8c65f4484ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#qqqq <- miceAuto_RF(test4, num_iterations)\n",
    "print(typeof(qqqq))\n",
    "print(length(qqqq))\n",
    "print(\"XXXXXXXX\")\n",
    "print(typeof(qqqq[[1]]))\n",
    "print(length(qqqq[[1]]))\n",
    "print(qqqq)\n",
    "print(qqqq[[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94287034-afee-41fb-897f-c94b45961647",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''qqqqq <- miceAuto_log(test5, num_iterations)\n",
    "print(typeof(qqqqq))\n",
    "print(length(qqqqq))\n",
    "print(\"XXXXXXXX\")\n",
    "print(typeof(qqqqq[[1]]))\n",
    "print(length(qqqqq[[1]]))\n",
    "print(qqqqq)\n",
    "print(qqqqq[[1]])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923578e3-136b-4bff-b739-379140abd5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''qqqqqq <- miceAuto_logregboot(test6, num_iterations)\n",
    "print(typeof(qqqqqq))\n",
    "print(length(qqqqqq))\n",
    "print(\"XXXXXXXX\")\n",
    "print(typeof(qqqqqq[[1]]))\n",
    "print(length(qqqqqq[[1]]))\n",
    "print(qqqqqq)\n",
    "print(qqqqqq[[1]])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022918ca-5bf9-4f0e-a2cb-22cd0f07e778",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#qqqqqq <- missForest_Impute(test6, num_iterations)\n",
    "print(typeof(qqqqqq))\n",
    "print(length(qqqqqq))\n",
    "print(\"XXXXXXXX\")\n",
    "print(typeof(qqqqqq[[1]]))\n",
    "print(length(qqqqqq[[1]]))\n",
    "print(qqqqqq)\n",
    "print(qqqqqq[[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcb9fe6-05f8-48b3-8710-17ac14157d08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(test7[[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841b169c-fbb5-40fd-973d-79e21b360fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''library(devtools)\n",
    "Sys.setenv(PATH = paste(\"C:\\\\rtools44\\\\mingw_64\\\\bin\", Sys.getenv(\"PATH\"), sep=\";\"))\n",
    "Sys.setenv(BINPREF = \"C:\\\\rtools44\\\\mingw_64\\\\bin\\\\\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846a584e-8716-4931-9491-82d9647c17e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''library(devtools)\n",
    "Sys.setenv(PATH = paste(\"C:\\\\Users\\\\J\\\\ANACON~1\\\\envs\\\\R_ENVI~1\\\\Rtools\\\\mingw_64\\\\bin\", Sys.getenv(\"PATH\"), sep=\";\"))\n",
    "Sys.setenv(BINPREF = \"C:\\\\Users\\\\J\\\\ANACON~1\\\\envs\\\\R_ENVI~1\\\\Rtools\\\\mingw_64\\\\bin\\\\\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6edfe44-71a9-4f65-aa86-827d9c8bf6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''library(devtools)\n",
    "Sys.setenv(PATH = paste(\"C:\\\\Users\\\\J\\\\ANACON~1\\\\envs\\\\R_ENVI~1\\\\Rtools\\\\mingw_64\\\\bin\", Sys.getenv(\"PATH\"), sep=\";\"))\n",
    "Sys.setenv(BINPREF = \"C:\\\\Users\\\\J\\\\ANACON~1\\\\envs\\\\R_ENVI~1\\\\Rtools\\\\mingw_64\\\\bin\\\\\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2977e86-d2d8-4170-b67c-10871e661e46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''Sys.which(\"g++\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cccba9-6778-4dd8-8e29-5698a099ade7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''system(\"g++ -v\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b7be65-ab62-4c9f-ae74-97c27fda7366",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Sys.which(\"Rtools\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1663de4-7af3-4ea7-b254-27064675ce07",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''install.packages(\"ggplot2\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eefc50f-bf66-46ef-ac69-57340584a5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''install.packages(c(\"farver\", \"cli\", \"lifecycle\", \"rlang\", \"scales\", \"vctrs\"))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff44a430-f7de-49dd-bd67-6f662e0c13de",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Sys.which(\"gcc\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786d0395-dbce-4581-a71b-5c3440958751",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''library(ggplot2)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047d5003-1065-45a7-9d49-7b4739168328",
   "metadata": {},
   "outputs": [],
   "source": [
    "update.packages(ask = FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959af49a-7743-438b-a9ea-6bf02719b250",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit1 <- brm(Length ~ Width + Height,\n",
    "            data = q[[1]], family = gaussian())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d8b70b-ca45-4086-95c1-46b7b167ef93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbdc965-bb2d-4983-8b40-4a5998cd300b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484cf8c1-7644-4ef2-8f5d-7adfb6ce132c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d29c147-e8eb-4a9e-aabc-914b62b0f89a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58aa7dfe-ba70-4418-900a-32ac409d3979",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test <- list()\n",
    "test <- df_list\n",
    "num_iterations <- list(1, 3)\n",
    "#print(num_iterations[[1]])\n",
    "#print(typeof(test))\n",
    "#print(length(test))\n",
    "qqq <- miceAuto_pmm(test, num_iterations)\n",
    "print(length(qqq))\n",
    "#testing <- test[[1]]\n",
    "#testinging <- testing[[1]]\n",
    "#print(length(testinging))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88064ef5-a0fe-4fcf-8c5c-5e620e6e9816",
   "metadata": {},
   "outputs": [],
   "source": [
    "#confirmed works. retunrs full dataframes\n",
    "miceAuto_logregboot <- function(df_list, num_interations) {\n",
    "    complete_mice_imputed_data_final <- list()\n",
    "\n",
    "    # Iterate through dfs in df_list\n",
    "    for (i in 1:length(df_list)) {        \n",
    "        # Iterate through each num_interations\n",
    "        for (j in num_iterations) {\n",
    "            # Process each data table and save the output to the new list\n",
    "            mice_imputed_data <- mice(df_list[[i]], method = \"logreg.boot\", m = j)\n",
    "            complete_mice_imputed_data <- complete(mice_imputed_data,j)\n",
    "            complete_mice_imputed_data_final[[paste0(\"df\", i, \"_imp\", j)]] <- as.data.frame(complete_mice_imputed_data)\n",
    "            print(complete_mice_imputed_data_final)\n",
    "            }\n",
    "        }\n",
    "    return (complete_mice_imputed_data_final)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe2359a-202c-4d54-a0a9-4d0e354edc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "a <- clean_onlyImputed(qqq, test)\n",
    "print(typeof(a))\n",
    "print(length(a))\n",
    "print(length(a[[1]]))\n",
    "a[[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48dadbd5-b1f9-46d8-ad07-46fc8e0e1df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#works as intended\n",
    "create_dict_for_PYMICE_imputation <- function(df_list, df_PYMICE_dict, threshold_list, percentage_list, \n",
    "                                              max_iter_list, imputation) {\n",
    "    dataset_index <- 1\n",
    "  \n",
    "    for (v_value in threshold_list) {\n",
    "        for (vv_value in percentage_list) {\n",
    "            for (vvv_value in max_iter_list) {\n",
    "                entry <- list(\"dataframe\" = df_list[[dataset_index]], \"stdev_thresh\" = v_value, \n",
    "                \"missing_percent\" = vv_value, \"iterations\" = vvv_value, \"MICE_imputation\" = imputation)\n",
    "                df_PYMICE_dict[[dataset_index]] <- entry\n",
    "                dataset_index <- dataset_index + 1\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "  \n",
    "    print(\"Dictionary: dataframe, stdev_thresh, missing_percent, iterations, MICE_imputation\")\n",
    "    return(df_PYMICE_dict)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf61234-0323-4a45-8399-6cc99fda4075",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_list <- list(2, 3)\n",
    "percentage_list <- list(5, 15, 35)\n",
    "max_iter_list <- list(1, 3)\n",
    "df_PYMICE_dict <- list()\n",
    "aa <- a\n",
    "imputation <- \"pmm\"\n",
    "qw <- create_dict_for_PYMICE_imputation(aa, df_PYMICE_dict, threshold_list, percentage_list, max_iter_list, imputation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af33c33b-9d74-4bda-91f8-da521b86f3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(typeof(qw))\n",
    "print(length(qw))\n",
    "print(length(qw[[1]]))\n",
    "qw[[1]][[\"missing_percent\"]]\n",
    "for (i in qw) {\n",
    "    print (i[[\"missing_percent\"]])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2af47d4-0ea8-47ba-a26b-3302eae16a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df <- as.data.frame(qw)\n",
    "directory <- \"C:\\\\Users\\\\J\\\\Outputs_From_R\"\n",
    "R_dict <- \"df_dictionary_R.csv\"\n",
    "file_path <- file.path(directory, file_name)\n",
    "write.csv(df, file = file_path, row.names = FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5318e367-a44d-4285-b7e6-a2b1b384a1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list <- as.data.frame(a)\n",
    "directory <- \"C:\\\\Users\\\\J\\\\Outputs_From_R\"\n",
    "R_dict <- \"imputed_values_R.csv\"\n",
    "file_path <- file.path(directory, file_name)\n",
    "write.csv(df, file = file_path, row.names = FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482b545d-b7b8-4154-8622-c71ee76d3640",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(packageVersion(\"missForest\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8460ca-9839-40e7-b53b-c27700d10139",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4530392d-6a95-4628-8bcc-2737d9361971",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for reference from python\n",
    "def create_dict_for_PYMICE_imputation(df_list, df_PYMICE_dict, threshold_list, percentage_list, max_iter_list):\n",
    "    dataset_index = 0\n",
    "\n",
    "    for v_index, v_value in enumerate(threshold_list):\n",
    "        for vv_value in percentage_list:\n",
    "            for vvv_value in max_iter_list:\n",
    "                entry = {'dataframe': df_list[v_index], 'stdev_thresh': v_value,\n",
    "                         'missing_percent' : vv_value, 'iterations' : vvv_value}\n",
    "                df_PYMICE_dict[dataset_index] = entry\n",
    "                dataset_index += 1\n",
    "\n",
    "    print(\"Dictionary: dataframe, stdev_thresh, missing_percent, iterations\")\n",
    "    return df_PYMICE_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955d422c-904e-46c1-8780-93298457b0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def miceMethod(df_list, max_iter_list):\n",
    "    df_MICE_imputed_list = []\n",
    "    df_imputed_values_list = []\n",
    "    \n",
    "    for df in df_list:\n",
    "        for max_iterA in max_iter_list:\n",
    "            # Create an instance of the MICE imputer\n",
    "            mice_imputer = IterativeImputer(max_iter=max_iterA)\n",
    "\n",
    "            # Impute missing values using the MICE algorithm\n",
    "            df_imputed = mice_imputer.fit_transform(df)\n",
    "\n",
    "            # Convert the imputed array back to a DataFrame\n",
    "            df_MICE_imputed = pd.DataFrame(df_imputed, columns=df.columns, index=df.index)\n",
    "\n",
    "            # Create a DataFrame with just the imputed values\n",
    "            df_imputed_values = df_MICE_imputed[df.isna()]\n",
    "\n",
    "            # Append the imputed DataFrames to the respective lists\n",
    "            df_MICE_imputed_list.append(df_MICE_imputed)\n",
    "            df_imputed_values_list.append(df_imputed_values)\n",
    "\n",
    "    return df_MICE_imputed_list, df_imputed_values_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d771af9-fb0c-4c33-8367-2ea767f8e101",
   "metadata": {},
   "outputs": [],
   "source": [
    "#confirmed works\n",
    "\n",
    "pureImputedValues_fromList <- function(df_OGdata_with_missing, df_full_with_imputations) {\n",
    "    imputed_values_df_final <- list()\n",
    "\n",
    "    # Iterate through each data table in the list. Ensure that the correct datatables are being used! Equivalent index values!\n",
    "    for (i in 1:length(df_list)) {\n",
    "        # Compare data from each df\n",
    "        imputed_values <- is.na(df_OGdata_with_missing[[i]]) & !is.na(df_full_with_imputations[[i]])\n",
    "\n",
    "        # Extract the V1 column from the original dataframe\n",
    "        V1_column <- df_OGdata_with_missing[[i]]$V1\n",
    "\n",
    "        # Create a copy of the imputed dataframe\n",
    "        imputed_values_df <- df_full_with_imputations[[i]]\n",
    "\n",
    "        # Replace non-imputed values with NA in the copied dataframe\n",
    "        imputed_values_df[!imputed_values] <- NA\n",
    "\n",
    "        # Add the V1 column to the copied dataframe\n",
    "        imputed_values_df$V1 <- V1_column\n",
    "\n",
    "        # Convert the imputed values to a dataframe if needed\n",
    "        imputed_values_df_final[[i]] <- as.data.frame(imputed_values_df)\n",
    "\n",
    "        }\n",
    "    print(imputed_values_df_final)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83db6a9f-4e59-4591-a750-3d119d6f4cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram <- function(df) {\n",
    "    # Create a ggplot object with geom_histogram for each column\n",
    "    L <- ggplot(df, aes(x = Length)) + geom_histogram(color = \"#000000\", fill = \"#0099F8\") +\n",
    "    ggtitle(\"Length Distribution\") + theme_classic() + theme(plot.title = element_text(size = 18))\n",
    " \n",
    "    # Add geom_histogram for the Width column\n",
    "    W <- ggplot(df, aes(x = Width)) + geom_histogram(color = \"#000000\", fill = \"#0099F8\") +\n",
    "    ggtitle(\"Width Distribution\") + theme_classic() + theme(plot.title = element_text(size = 18))\n",
    "  \n",
    "    # Add geom_histogram for the Height column\n",
    "    H <- ggplot(df, aes(x = Height)) + geom_histogram(color = \"#000000\", fill = \"#0099F8\") +\n",
    "    ggtitle(\"Height Distribution\") + theme_classic() + theme(plot.title = element_text(size = 18))\n",
    "  \n",
    "    return(list(L, W, H))\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920f8ad2-46bb-472c-85c8-6cd9b7753853",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_list <- list()\n",
    "list_of_datatables <- df_list\n",
    "\n",
    "# Iterate through each data table in the list\n",
    "for (i in 1:length(list_of_datatables)) {\n",
    "    # Process each data table and save the output to the new list\n",
    "    processed_data <- plot_histogram(list_of_datatables[[i]])\n",
    "    new_list[[i]] <- processed_data\n",
    "}\n",
    "\n",
    "new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5ae2e4-83c5-47b2-afca-5744fab2a6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''df <- df_list[[4]]\n",
    "for (col in names(df)) {\n",
    "    print(ggplot(df, aes(x = .data[[col]])) +\n",
    "    geom_histogram(color = \"#000000\", fill = \"#0099F8\") +\n",
    "    ggtitle(\"Variable distribution\") +\n",
    "    theme_classic() +\n",
    "    theme(plot.title = element_text(size = 18))\n",
    "    )}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc74460-ef35-4c0e-848a-dcc647449372",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1 <- df_list[[4]][[\"Height\"]]\n",
    "df2 <- df_list[[4]]\n",
    "#df1\n",
    "#df2\n",
    "#df3 <- df2[, c(\"V1\", \"Length\"), with = FALSE]\n",
    "#df3\n",
    "#df3 <- as.data.frame(df3)\n",
    "df2 <- as.data.frame(df2)\n",
    "#md.pattern(df2)\n",
    "df2\n",
    "\n",
    "#tempData <- mice(df2,m=5,maxit=50,meth='pmm',seed=500)\n",
    "#summary(tempData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b71c9d-3205-4f78-a7ca-4e8ce6d9b4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#confirmed this works\n",
    "miceAuto <- function(df_list) {\n",
    "    complete_mice_imputed_data_final <- list()\n",
    "    \n",
    "    # Iterate through each data table in the list\n",
    "    for (i in 1:length(df_list)) {\n",
    "        # Process each data table and save the output to the new list\n",
    "        mice_imputed_data <- mice(df_list[[i]], method = \"pmm\", m = 5)\n",
    "        complete_mice_imputed_data <- complete(mice_imputed_data,1)\n",
    "        complete_mice_imputed_data_final[[i]] <- as.data.frame(complete_mice_imputed_data)\n",
    "        }\n",
    "    print(complete_mice_imputed_data_final)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086134fb-1166-4471-afc1-eeb0ee97434c",
   "metadata": {},
   "outputs": [],
   "source": [
    "miceAuto <- function(df_list) {\n",
    "    # Iterate through each data table in the list\n",
    "    for (i in 1:length(df_list)) {\n",
    "        # Process each data table and save the output to the new list\n",
    "        mice_imputed_data <- mice(list_of_datatables[[i]], method = \"pmm\", m = 5)\n",
    "        complete_mice_imputed_data <- complete(mice_imputed_data,1)\n",
    "        }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1763add3-28f3-453f-ab44-f46efb62ad5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test <- list()\n",
    "test <- df_list\n",
    "num_iterations <- list(3, 5, 10)\n",
    "print(num_iterations[[1]])\n",
    "qqq <- miceAuto1(test)\n",
    "typeof(qqq)\n",
    "length(qqq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a7f9f2-1ed6-466c-91b3-6230753e4967",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(qqq[[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9684d8f-fc77-492d-9e80-7b755e2b60ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "test <- list()\n",
    "test <- df_list\n",
    "qq <- miceAuto(test)\n",
    "qq[[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5977b747-03fc-4e05-abd6-427d0e66e5a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132930d7-28cf-4e54-b109-b1e99bb37882",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 <- as.data.frame(df2)\n",
    "# Loop through each CSV file\n",
    "for (file in csv_files) {\n",
    "  # Read the CSV file into a data.table\n",
    "  df <- fread(file)\n",
    "  \n",
    "  # Add the data.table to the list\n",
    "  df_list[[file]] <- df\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11c3230-1dab-4a74-9952-ea0097e2a53c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imputed <- mice(df2, method = \"pmm\", m = 5)\n",
    "#summary(imputed)\n",
    "completedData <- complete(imputed,1)\n",
    "completedData1 <- complete(imputed,5)\n",
    "summary(completedData)\n",
    "summary(completedData1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660f8055-591e-4f79-9cb9-153ae0fe00ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "pureImputedValues_fromList <- function(df_OGdata_with_missing, df_full_with_imputations) {\n",
    "    imputed_values_df_final <- list()\n",
    "\n",
    "    # Iterate through each data table in the list. Ensure that the correct datatables are being used! Equivalent index values!\n",
    "    for (i in 1:length(df_list)) {\n",
    "        # Compare data from each df\n",
    "        imputed_values <- is.na(df_OGdata_with_missing[[i]]) & !is.na(df_full_with_imputations[[i]])\n",
    "\n",
    "        # Extract the V1 column from the original dataframe\n",
    "        V1_column <- df_OGdata_with_missing[[i]]$V1\n",
    "\n",
    "        # Create a copy of the imputed dataframe\n",
    "        imputed_values_df <- df_full_with_imputations[[i]]\n",
    "\n",
    "        # Replace non-imputed values with NA in the copied dataframe\n",
    "        imputed_values_df[!imputed_values] <- NA\n",
    "\n",
    "        # Add the V1 column to the copied dataframe\n",
    "        imputed_values_df$V1 <- V1_column\n",
    "\n",
    "        # Convert the imputed values to a dataframe if needed\n",
    "        imputed_values_df_final <- as.data.frame(imputed_values_df)\n",
    "\n",
    "        }\n",
    "    print(imputed_values_df_final)\n",
    "}\n",
    "\n",
    "pureImputedValues <- function(df_OGdata_with_missing, df_full_with_imputations) {\n",
    "    # Compare data from each df\n",
    "    imputed_values <- is.na(df_OGdata_with_missing) & !is.na(df_full_with_imputations)\n",
    "\n",
    "    # Extract the V1 column from the original dataframe\n",
    "    V1_column <- df_OGdata_with_missing$V1\n",
    "\n",
    "    # Create a copy of the imputed dataframe\n",
    "    imputed_values_df <- df_full_with_imputations\n",
    "\n",
    "    # Replace non-imputed values with NA in the copied dataframe\n",
    "    imputed_values_df[!imputed_values] <- NA\n",
    "\n",
    "    # Add the V1 column to the copied dataframe\n",
    "    imputed_values_df$V1 <- V1_column\n",
    "\n",
    "    # Convert the imputed values to a dataframe if needed\n",
    "    imputed_values_df <- as.data.frame(imputed_values_df)\n",
    "\n",
    "    print(imputed_values_df)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e218e124-7c4e-489b-a241-9aac8bbeeae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa <- pureImputedValues_fromList(test, qq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e436f32-e9bb-47f0-8a9c-c4ac511e56a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this works and has been tested\n",
    "pureImputedValues <- function(df_OGdata_with_missing, df_full_with_imputations) {\n",
    "    # Compare data from each df\n",
    "    imputed_values <- is.na(df_OGdata_with_missing) & !is.na(df_full_with_imputations)\n",
    "\n",
    "    # Extract the V1 column from the original dataframe\n",
    "    V1_column <- df_OGdata_with_missing$V1\n",
    "\n",
    "    # Create a copy of the imputed dataframe\n",
    "    imputed_values_df <- df_full_with_imputations\n",
    "\n",
    "    # Replace non-imputed values with NA in the copied dataframe\n",
    "    imputed_values_df[!imputed_values] <- NA\n",
    "\n",
    "    # Add the V1 column to the copied dataframe\n",
    "    imputed_values_df$V1 <- V1_column\n",
    "\n",
    "    # Convert the imputed values to a dataframe if needed\n",
    "    imputed_values_df <- as.data.frame(imputed_values_df)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6979e279-d69a-494c-b94a-e546c1066575",
   "metadata": {},
   "outputs": [],
   "source": [
    "pureImputedValues <- function(df_OGdata_with_missing, df_full_with_imputations) {\n",
    "    # Compare data from each df\n",
    "    imputed_values <- is.na(df_OGdata_with_missing) & !is.na(df_full_with_imputations)\n",
    "\n",
    "    # Extract the V1 column from the original dataframe\n",
    "    V1_column <- df_OGdata_with_missing$V1\n",
    "\n",
    "    # Create a copy of the imputed dataframe\n",
    "    imputed_values_df <- df_full_with_imputations\n",
    "\n",
    "    # Replace non-imputed values with NA in the copied dataframe\n",
    "    imputed_values_df[!imputed_values] <- NA\n",
    "\n",
    "    # Add the V1 column to the copied dataframe\n",
    "    imputed_values_df$V1 <- V1_column\n",
    "\n",
    "    # Convert the imputed values to a dataframe if needed\n",
    "    imputed_values_df <- as.data.frame(imputed_values_df)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21dff49-9ee6-47c3-95b0-19ff2961219b",
   "metadata": {},
   "outputs": [],
   "source": [
    "xxx <-pureImputedValues(df2, completedData)\n",
    "xxx[[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d0ea47-65d7-46c1-9516-b4931ae65019",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imputed_values <- is.na(df2) & !is.na(completedData)\n",
    "\n",
    "# Extract the V1 column from the original dataframe\n",
    "V1_column <- df2$V1\n",
    "\n",
    "# Create a copy of the imputed dataframe\n",
    "imputed_values_df <- completedData\n",
    "\n",
    "# Replace non-imputed values with NA in the copied dataframe\n",
    "imputed_values_df[!imputed_values] <- NA\n",
    "\n",
    "# Add the V1 column to the copied dataframe\n",
    "imputed_values_df$V1 <- V1_column\n",
    "\n",
    "# Convert the imputed values to a dataframe if needed\n",
    "imputed_values_df <- as.data.frame(imputed_values_df)\n",
    "\n",
    "print(imputed_values_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f6e04a-b840-4505-adb3-4f5f4501a317",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711ef82a-ac24-427e-86e2-f8439e822d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mice_imputed <- data.frame(\n",
    "  original = titanic_train$Age,\n",
    "  imputed_pmm = complete(mice(titanic_numeric, method = \"pmm\"))$Age,\n",
    "  imputed_cart = complete(mice(titanic_numeric, method = \"cart\"))$Age,\n",
    "  imputed_lasso = complete(mice(titanic_numeric, method = \"lasso.norm\"))$Age\n",
    ")\n",
    "mice_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5569b28f-f047-442e-b278-cb91fe4c049e",
   "metadata": {},
   "outputs": [],
   "source": [
    "perform_imputations <- function(df_list, MICEfunc, num_imputations) {\n",
    "    # Specify the column names to iterate over\n",
    "    column_names <- c(\"Length\", \"Width\", \"Height\")\n",
    "  \n",
    "    # Initialize an empty list to store the imputed data frames\n",
    "    imputed_list <- list()\n",
    "  \n",
    "    # Iterate over each data frame in the list\n",
    "    for (df in df_list) {\n",
    "        # Initialize an empty data frame to store the imputed values\n",
    "        imputed_df <- data.frame(original = numeric(0))\n",
    "    \n",
    "        # Iterate over each column name\n",
    "        for (col_name in column_names) {\n",
    "            # Perform multiple imputations on the current column\n",
    "            imputed_col <- complete(mice(df[, ..col_name, drop = FALSE], method = MICEfunc, m = num_imputations))[[col_name]]\n",
    "      \n",
    "            # Combine the imputed column with the existing imputed data frame\n",
    "            imputed_df <- cbind(imputed_df, imputed_col)\n",
    "            }\n",
    "    \n",
    "        # Remove the empty original column and append the imputed data frame to the list\n",
    "        imputed_df <- imputed_df[, -1]\n",
    "        imputed_list <- c(imputed_list, list(imputed_df))\n",
    "        }\n",
    "  \n",
    "    return(imputed_list)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7fd1c2-c407-44f4-a240-1a48b71431ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage example\n",
    "imputed_data <- perform_imputations(df_list, \"pmm\", 3)\n",
    "\n",
    "\n",
    "# Usage example\n",
    "#imputed_data <- perform_imputations(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f2d9dc-6973-47e0-8c11-5b64bda13f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mice_imputed <- data.frame(\n",
    "  original = df3$Length,\n",
    "  imputed_pmm = complete(mice(df3, method = \"pmm\"))$Length,\n",
    "  imputed_cart = complete(mice(df3, method = \"cart\"))$Length,\n",
    "  imputed_lasso = complete(mice(df3, method = \"lasso.norm\"))$Length\n",
    ")\n",
    "mice_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b3f4f8-3849-4a8b-9086-027a98a6582a",
   "metadata": {},
   "outputs": [],
   "source": [
    "perform_imputations <- function(df_list, MICEfunc, num_imputations) {\n",
    "    # Specify the column name to iterate over\n",
    "    column_name <- \"Height\"\n",
    "  \n",
    "    # Initialize an empty list to store the imputed data frames\n",
    "    imputed_list <- list()\n",
    "  \n",
    "    # Iterate over each data frame in the list\n",
    "    for (df in df_list) {\n",
    "        # Perform multiple imputations on the current column\n",
    "        imputed_col <- complete(mice(df[, column_name, drop = FALSE], method = MICEfunc, m = num_imputations))[[column_name]]\n",
    "      \n",
    "        # Append the imputed data frame to the list\n",
    "        imputed_list <- c(imputed_list, list(imputed_col))\n",
    "    }\n",
    "  \n",
    "    return(imputed_list)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b8413b-73a4-47ba-b772-c40573692c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "x <- perform_imputations(df, \"pmm\", 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f4b624-d4ea-4dbf-9abe-e84f2657109b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df <- df_list[[4]]\n",
    "\n",
    "imputed_df <- lapply(df, function(x) {\n",
    "    if (is.numeric(x)) {\n",
    "    replace(x, is.na(x), mean(x, na.rm = TRUE))\n",
    "  } else {\n",
    "    x\n",
    "  }\n",
    "})\n",
    "# Convert the list back to a data frame\n",
    "imputed_df <- as.data.frame(imputed_df)\n",
    "\n",
    "# Print the imputed data frame\n",
    "print(imputed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6713b286-d092-404a-aed1-4b61c80100de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242b7e5c-e195-499c-a063-2c20ccfa865d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42e7100-5da8-4359-bd8c-a58eba137565",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c912249-40f7-42fe-a504-d31187fbeeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def NaNfilter(df_list):\n",
    "    filtered_dfs = []  # List to store the filtered DataFrames\n",
    "    for df in df_list:\n",
    "        filtered_cols = {}  # Dictionary to store filtered columns for each DataFrame\n",
    "        print(\"DataFrame:\")\n",
    "        for column in df.columns:\n",
    "            dropped_col = df[column].dropna()\n",
    "            filtered_cols[column] = dropped_col  # Store filtered column in dictionary\n",
    "            print(column, '\\n', dropped_col)\n",
    "        filtered_df = pd.DataFrame(filtered_cols)  # Convert filtered columns dictionary to DataFrame\n",
    "        filtered_dfs.append(filtered_df)  # Append filtered DataFrame to the list\n",
    "    return filtered_dfs'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9be580-1801-4182-b952-48fec454c5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NaNfilter(df_list):\n",
    "    filtered_dfs = []  # List to store the filtered DataFrames\n",
    "    for df in df_list:\n",
    "        filtered_cols = {}  # Dictionary to store filtered columns for each DataFrame\n",
    "        for column in df.columns:\n",
    "            dropped_col = df[column].dropna()\n",
    "            filtered_cols[column] = dropped_col  # Store filtered column in dictionary\n",
    "            print(dropped_col.to_string(header=False))  # Print non-null values without header\n",
    "            #print(column, '\\n', dropped_col)\n",
    "        filtered_df = pd.DataFrame(filtered_cols)  # Convert filtered columns dictionary to DataFrame\n",
    "        filtered_dfs.append(filtered_df)  # Append filtered DataFrame to the list\n",
    "    return filtered_dfs\n",
    "\n",
    "def accuracy(groundTruth, predictedData):\n",
    "    groundTruth = np.array(groundTruth, dtype=np.float64)\n",
    "    predictedData = np.array(predictedData, dtype=np.float64)\n",
    "    delta = groundTruth - predictedData\n",
    "    accuracyPercent = (delta / groundTruth * 100)\n",
    "    accuracyPercent = np.round(accuracyPercent, 2)\n",
    "    min = np.round(np.min(accuracyPercent), 2)\n",
    "    max = np.round(np.max(accuracyPercent), 2)\n",
    "    mean = np.round(np.mean(accuracyPercent), 2)\n",
    "    return print(accuracyPercent, '\\n', 'Minimum %:', min, '\\n', 'Maximum %:', max, '\\n', 'Average Accuracy %:', mean)\n",
    "\n",
    "def mse(groundTruth, predictedData):\n",
    "    mse = mean_squared_error(groundTruth, predictedData)\n",
    "    return print(\"Mean Squared Error (MSE): \", np.round(mse, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73f9750-a03f-4b10-9d8a-175bc8ae5069",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NaNfilterPrint(df_list):\n",
    "    cleaned = []  # List to store cleaned dataframes\n",
    "    for df in df_list:\n",
    "        dropped_cols = []  # List to store dropped columns for each dataframe\n",
    "        for column in df.columns:\n",
    "            dropped_col = df[column].dropna().tolist()  # Convert dropped column to list\n",
    "            dropped_cols.append(dropped_col)  # Append dropped column to list\n",
    "        cleaned.append(dropped_cols)  # Append dropped columns for this dataframe to cleaned list\n",
    "    return pd.DataFrame(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839c5096-ad92-464a-84fc-212ff1e78c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NaNfilter(df_list):\n",
    "    cleaned = []  # List to store cleaned dataframes\n",
    "    for df in df_list:\n",
    "        dropped_cols = []  # List to store dropped columns for each dataframe\n",
    "        for column in df.columns:\n",
    "            dropped_col = df[column].dropna().tolist()  # Convert dropped column to list\n",
    "            dropped_cols.append(dropped_col)  # Append dropped column to list\n",
    "        cleaned.append(dropped_cols)  # Append dropped columns for this dataframe to cleaned list\n",
    "    return cleaned\n",
    "\n",
    "def accuracy(groundTruth, predictedData):\n",
    "    groundTruth = np.array(groundTruth, dtype=np.float64)\n",
    "    predictedData = np.array(predictedData, dtype=np.float64)\n",
    "    delta = groundTruth - predictedData\n",
    "    accuracyPercent = (delta / groundTruth * 100)\n",
    "    accuracyPercent = np.round(accuracyPercent, 2)\n",
    "    min = np.round(np.min(accuracyPercent), 2)\n",
    "    max = np.round(np.max(accuracyPercent), 2)\n",
    "    mean = np.round(np.mean(accuracyPercent), 2)\n",
    "    return print(accuracyPercent, '\\n', 'Minimum %:', min, '\\n', 'Maximum %:', max, '\\n', 'Average Accuracy %:', mean)\n",
    "\n",
    "def mse(groundTruth, predictedData):\n",
    "    mse = mean_squared_error(groundTruth, predictedData)\n",
    "    return print(\"Mean Squared Error (MSE): \", np.round(mse, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a4479d-ff71-49f5-a11c-7b69d6c3ec41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imputed = NaNfilter(imputed_values)\n",
    "G_T = NaNfilter(GT)\n",
    "print(type(G_T))\n",
    "print(type(imputed))\n",
    "print(len(G_T))\n",
    "print(len(imputed))\n",
    "print(type(G_T[0]))\n",
    "print(len(G_T[0]))\n",
    "print(type(imputed[0]))\n",
    "print(len(imputed[0]))\n",
    "#print(G_T[0])\n",
    "print(\"xxxxxxxxxxxxxxxxxxxxxx\")\n",
    "xxx = pd.DataFrame(G_T)\n",
    "zzz = pd.DataFrame(imputed)\n",
    "print(xxx.shape)\n",
    "print(zzz.shape)\n",
    "print(\n",
    "print(type(xxx))\n",
    "print(len(xxx))\n",
    "print(xxx)\n",
    "\n",
    "print(type(xxx[0]))\n",
    "print(len(xxx[0]))\n",
    "print(xxx[0])\n",
    "\n",
    "#at this point "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b587a6-70a9-44f1-b5ed-1db8265c5704",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def MICE_scoring(df_from_split, df_MICEd):\n",
    "\n",
    "    aa = df_from_split[1] # df GT\n",
    "    mm = df_MICEd[1] # only the imputed values\n",
    "    \n",
    "    filt_GT = NaNfilter(aa)\n",
    "    filt_pred = NaNfilter(mm)\n",
    "\n",
    "    for gt, imputation_set in zip(filt_GT, filt_pred):\n",
    "        dataset_scores = []\n",
    "        for i in range(0, len(imputation_set), 3):\n",
    "            # Extract the MICE imputations for this dataset\n",
    "            imputations = imputation_set[i:i+3]\n",
    "            \n",
    "            # Calculate accuracy and MSE for each imputation\n",
    "            for imp in imputations:\n",
    "                impute_accuracy = accuracy(gt, imp)\n",
    "                impute_mse = mse(gt, imp)\n",
    "                \n",
    "                dataset_scores.append((impute_accuracy, impute_mse))\n",
    "    \n",
    "    return'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50a663f-9bbb-43ae-9e08-e077461a868a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NaNfilter(df_list):\n",
    "    filtered_dfs = []  # List to store the filtered DataFrames\n",
    "    for df in df_list:\n",
    "        filtered_cols = []  # List to store filtered columns for each DataFrame\n",
    "        for column in df.columns:\n",
    "            filtered_col = df[column].dropna().tolist()  # Convert Series to list\n",
    "            filtered_cols.append(filtered_col)  # Append filtered column to list\n",
    "        filtered_dfs.append(filtered_cols)  # Append filtered columns to the list\n",
    "    return filtered_dfs\n",
    "\n",
    "\n",
    "def accuracy(groundTruth, predictedData):\n",
    "    print(\"Ground Truth:\", groundTruth)\n",
    "    print(\"Predicted Data:\", predictedData)\n",
    "    groundTruth = np.array(groundTruth, dtype=np.float64)\n",
    "    predictedData = np.array(predictedData, dtype=np.float64)\n",
    "    delta = groundTruth - predictedData\n",
    "    accuracyPercent = (delta / groundTruth * 100)\n",
    "    accuracyPercent = np.round(accuracyPercent, 2)\n",
    "    min_accuracy = np.round(np.min(accuracyPercent), 2)\n",
    "    max_accuracy = np.round(np.max(accuracyPercent), 2)\n",
    "    mean_accuracy = np.round(np.mean(accuracyPercent), 2)\n",
    "    return accuracyPercent, min_accuracy, max_accuracy, mean_accuracy\n",
    "\n",
    "\n",
    "\n",
    "def mse(groundTruth, predictedData):\n",
    "    mse = mean_squared_error(groundTruth, predictedData)\n",
    "    return print(\"Mean Squared Error (MSE): \", np.round(mse, 2))\n",
    "\n",
    "def MICE_scoring(df_from_split, df_MICEd):\n",
    "\n",
    "    aa = df_from_split[1]  # df GT\n",
    "    mm = df_MICEd[1]  # only the imputed values\n",
    "\n",
    "    filt_GT = pd.DataFrame(NaNfilter(aa))\n",
    "    filt_pred = pd.DataFrame(NaNfilter(mm))\n",
    "\n",
    "    dataset_scores = []\n",
    "    for col_gt, col_pred in zip(filt_GT.columns, filt_pred.columns):\n",
    "        # Extract the ground truth and corresponding imputation set\n",
    "        gt_col = filt_GT[col_gt]\n",
    "        imputation_set_col = filt_pred[col_pred]\n",
    "\n",
    "        # Calculate accuracy and MSE for each imputation in this column\n",
    "        impute_accuracy, min_accuracy, max_accuracy, mean_accuracy = accuracy(gt_col, imputation_set_col)\n",
    "        dataset_scores.append((impute_accuracy, min_accuracy, max_accuracy, mean_accuracy))\n",
    "\n",
    "    return dataset_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054dea8e-2be1-44db-97b2-7bf8a7697859",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MICE_scoring(df_from_split, df_MICEd):\n",
    "\n",
    "    aa = df_from_split[1]  # df GT\n",
    "    mm = df_MICEd[1]  # only the imputed values\n",
    "\n",
    "    filt_GT = pd.DataFrame(NaNfilter(aa))\n",
    "    filt_pred = pd.DataFrame(NaNfilter(mm))\n",
    "\n",
    "    dataset_scores = []\n",
    "    for col_gt, col_pred in zip(filt_GT.columns, filt_pred.columns):\n",
    "        # Extract the ground truth and corresponding imputation set\n",
    "        gt_col = filt_GT[col_gt]\n",
    "        imputation_set_col = pd.DataFrame(filt_pred[col_pred])  # Convert to DataFrame\n",
    "\n",
    "        # Calculate accuracy and MSE for each imputation in this column\n",
    "        num_imputations = len(imputation_set_col.columns)\n",
    "        for i in range(0, num_imputations, 3):\n",
    "            # Adjust the range to avoid exceeding the number of columns\n",
    "            end_index = min(i + 3, num_imputations)\n",
    "            \n",
    "            # Extract the MICE imputations for this column\n",
    "            imputations = imputation_set_col.iloc[:, i:end_index]\n",
    "\n",
    "            # Calculate accuracy and MSE for each imputation\n",
    "            for _, imp in imputations.items():\n",
    "                impute_accuracy = accuracy(gt_col, imp)\n",
    "                impute_mse = mse(gt_col, imp)\n",
    "\n",
    "                dataset_scores.append((impute_accuracy, impute_mse))\n",
    "\n",
    "    return dataset_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f999eb-aed1-48d5-a358-854491da7a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NaNfilter(df_list):\n",
    "    filtered_dfs = []  # List to store the filtered DataFrames\n",
    "    for df in df_list:\n",
    "        filtered_cols = []  # List to store filtered columns for each DataFrame\n",
    "        for column in df.columns:\n",
    "            filtered_col = df[column].dropna().tolist()  # Convert Series to list\n",
    "            filtered_cols.append(filtered_col)  # Append filtered column to list\n",
    "        filtered_dfs.append(filtered_cols)  # Append filtered columns to the list\n",
    "    return filtered_dfs\n",
    "\n",
    "\n",
    "def accuracy(groundTruth, predictedData):\n",
    "    print(\"Ground Truth:\", groundTruth)\n",
    "    print(\"Predicted Data:\", predictedData)\n",
    "    groundTruth = np.array(groundTruth, dtype=np.float64)\n",
    "    predictedData = np.array(predictedData, dtype=np.float64)\n",
    "    delta = groundTruth - predictedData\n",
    "    accuracyPercent = (delta / groundTruth * 100)\n",
    "    accuracyPercent = np.round(accuracyPercent, 2)\n",
    "    min_accuracy = np.round(np.min(accuracyPercent), 2)\n",
    "    max_accuracy = np.round(np.max(accuracyPercent), 2)\n",
    "    mean_accuracy = np.round(np.mean(accuracyPercent), 2)\n",
    "    return accuracyPercent, min_accuracy, max_accuracy, mean_accuracy\n",
    "\n",
    "\n",
    "def mse(groundTruth, predictedData):\n",
    "    mse = mean_squared_error(groundTruth, predictedData)\n",
    "    return print(\"Mean Squared Error (MSE): \", np.round(mse, 2))\n",
    "\n",
    "def MICE_scoring(df_from_split, df_MICEd):\n",
    "\n",
    "    aa = df_from_split[1]  # df GT\n",
    "    mm = df_MICEd[1]  # only the imputed values\n",
    "\n",
    "    filt_GT = pd.DataFrame(NaNfilter(aa))\n",
    "    filt_pred = pd.DataFrame(NaNfilter(mm))\n",
    "\n",
    "    dataset_scores = []\n",
    "    for col_gt, col_pred in zip(filt_GT.columns, filt_pred.columns):\n",
    "        # Extract the ground truth and corresponding imputation set\n",
    "        gt_col = filt_GT[col_gt]\n",
    "        imputation_set_col = filt_pred[col_pred]\n",
    "\n",
    "        # Calculate accuracy and MSE for each imputation in this column\n",
    "        impute_accuracy, min_accuracy, max_accuracy, mean_accuracy = accuracy(gt_col, imputation_set_col)\n",
    "        dataset_scores.append((impute_accuracy, min_accuracy, max_accuracy, mean_accuracy))\n",
    "\n",
    "    return dataset_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484eb89b-f3a9-4dfc-b77a-ef4a3d1959cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "q1q = MICE_scoring(aa, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4739ed-247d-4b41-adbf-760172154c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_imputations_with_ground_truth(df_from_split, df_MICEd):\n",
    "    scores = []\n",
    "\n",
    "    a = df_from_split[0] # df with missing values\n",
    "    aa = df_from_split[1] # df GT\n",
    "    \n",
    "    m = df_MICEd[0] # full imputated dataset\n",
    "    mm = df_MICEd[1] # only the imputed values\n",
    "\n",
    "    filt_GT = NaNfilterPrint(aa)\n",
    "    filt_pred = NaNfilterPrint(mm)\n",
    "\n",
    "    for gt, imputation_set in zip(filt_GT, filt_pred):\n",
    "        dataset_scores = []\n",
    "        for i in range(0, len(imputation_set), 3):\n",
    "            # Extract the MICE imputations for this dataset\n",
    "            imputations = imputation_set[i:i+3]\n",
    "\n",
    "            # Calculate scores for each imputation compared to the ground truth\n",
    "            imputation_scores = [MICE_scoring(gt, imp) for imp in imputations]\n",
    "\n",
    "            # Choose the best score as the final score for this dataset\n",
    "            scores.append(imputation_scores)\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65abe600",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_imputations_with_ground_truth(ground_truths, imputation_datasets):\n",
    "    scores = []\n",
    "\n",
    "    for gt, imputation_set in zip(ground_truths, imputation_datasets):\n",
    "        dataset_scores = []\n",
    "        for i in range(0, len(imputation_set), 3):\n",
    "            # Extract the MICE imputations for this dataset\n",
    "            imputations = imputation_set[i:i+3]\n",
    "\n",
    "            # Calculate scores for each imputation compared to the ground truth\n",
    "            imputation_scores = [calculate_score(gt, imp) for imp in imputations]\n",
    "\n",
    "            # Choose the best score as the final score for this dataset\n",
    "            dataset_scores.append(min(imputation_scores))\n",
    "\n",
    "        # Calculate the average score for this dataset\n",
    "        avg_score = sum(dataset_scores) / len(dataset_scores)\n",
    "        scores.append(avg_score)\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a48ccd-c437-445b-b8bc-f366963b4b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minMaxScaling(df):\n",
    "    minMixScaler = MinMaxScaler()\n",
    "    df_minMax = minMixScaler.fit_transform(df)\n",
    "    df_minMax_convert = pd.DataFrame(df_minMax, columns = df.columns)\n",
    "    return df_minMax_convert, minMixScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f048ad-2a18-4f5b-a842-6174bdbe637d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_minmax_scaler(data, scaler):\n",
    "    return scaler.inverse_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761e601f-e10f-4c61-ab9a-3d3ca4c4952f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_noOuts = df_no_Outliers[0].copy()\n",
    "df_sc = minMaxScaling(df_noOuts)\n",
    "print(df_sc[1])\n",
    "df_unsc = inverse_minmax_scaler(df_sc, df_sc[1])\n",
    "print(df_unsc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d225fd55-15f5-4cf6-b356-bdb5b2f30663",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8535d6be-0d07-4ecf-baac-10f2e6af7643",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c775748b-6234-4b04-b62b-e7d34ea90a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [\n",
    "    ('remove_outliers', zscoreGlobalOutlier(df_outlierthreshold, stdev_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a5de6d-1969-424f-8755-3215c29c77e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
